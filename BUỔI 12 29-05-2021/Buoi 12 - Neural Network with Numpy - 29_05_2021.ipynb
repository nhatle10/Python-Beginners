{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Buoi 12 - Neural Network with Numpy - 29/05/2021.ipynb","provenance":[],"toc_visible":true,"mount_file_id":"1-yp1injeoB7Zx7OLULlhuY6QExTNhUOR","authorship_tag":"ABX9TyMhgCDymbio7lmMgnQbwdHO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#  Buoi 12 | 29/05/2021 | Neural Network with Numpy\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1-yp1injeoB7Zx7OLULlhuY6QExTNhUOR?usp=sharing)"],"metadata":{"id":"c3xCPWMFTaBC"}},{"cell_type":"markdown","source":["## Import các thư viện cần thiết"],"metadata":{"id":"pG8uof-0sj-n"}},{"cell_type":"code","execution_count":44,"metadata":{"id":"PbLZMYgisGgD","executionInfo":{"status":"ok","timestamp":1643029093057,"user_tz":-420,"elapsed":712,"user":{"displayName":"Phạm Đức Thể","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0DbvnWDzLWfReqJkA_CpifKsPoGK79L7Ow3Jg1w=s64","userId":"09005724978234100310"}}},"outputs":[],"source":["import numpy as np\n","import os\n","import platform\n","import matplotlib.pyplot as plt\n","\n","\n","from builtins import range\n","from six.moves import cPickle as pickle\n","from imageio import imread"]},{"cell_type":"markdown","source":["## Load data"],"metadata":{"id":"p2HSz8GVspbJ"}},{"cell_type":"code","source":["def load_pickle(f):\n","    version = platform.python_version_tuple()\n","    if version[0] == \"2\":\n","        return pickle.load(f)\n","    elif version[0] == \"3\":\n","        return pickle.load(f, encoding=\"latin1\")\n","    raise ValueError(\"invalid python version: {}\".format(version))\n","\n","\n","def load_CIFAR_batch(filename):\n","    \"\"\" load single batch of cifar \"\"\"\n","    with open(filename, \"rb\") as f:\n","        datadict = load_pickle(f)\n","        X = datadict[\"data\"]\n","        Y = datadict[\"labels\"]\n","        X = X.reshape(10000, 3, 32, 32).transpose(0, 2, 3, 1).astype(\"float\")\n","        Y = np.array(Y)\n","        return X, Y\n","\n","\n","def load_CIFAR10(ROOT):\n","    \"\"\" load all of cifar \"\"\"\n","    xs = []\n","    ys = []\n","    for b in range(1, 6):\n","        f = os.path.join(ROOT, \"data_batch_%d\" % (b,))\n","        X, Y = load_CIFAR_batch(f)\n","        xs.append(X)\n","        ys.append(Y)\n","    Xtr = np.concatenate(xs)\n","    Ytr = np.concatenate(ys)\n","    del X, Y\n","    Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, \"test_batch\"))\n","    return Xtr, Ytr, Xte, Yte\n","\n","\n","def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, subtract_mean=True):\n","    \"\"\"\n","    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n","    it for classifiers. These are the same steps as we used for the SVM, but\n","    condensed to a single function.\n","    \"\"\"\n","    # Load the raw CIFAR-10 data\n","    cifar10_dir = os.path.join(os.path.dirname(__file__), \"/content/drive/MyDrive/TÀI LIỆU HỌC TẬP ĐẠI HỌC 2019-2023/PYTHON & ML 02/BUỔI 12 29 05 2021/data/cifar-10-batches-py\")\n","    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n","\n","    # Subsample the data\n","    mask = list(range(num_training, num_training + num_validation))\n","    X_val = X_train[mask]\n","    y_val = y_train[mask]\n","    mask = list(range(num_training))\n","    X_train = X_train[mask]\n","    y_train = y_train[mask]\n","    mask = list(range(num_test))\n","    X_test = X_test[mask]\n","    y_test = y_test[mask]\n","\n","    # Normalize the data: subtract the mean image\n","    if subtract_mean:\n","        mean_image = np.mean(X_train, axis=0)\n","        X_train -= mean_image\n","        X_val -= mean_image\n","        X_test -= mean_image\n","\n","    # Transpose so that channels come first\n","    X_train = X_train.transpose(0, 3, 1, 2).copy()\n","    X_val = X_val.transpose(0, 3, 1, 2).copy()\n","    X_test = X_test.transpose(0, 3, 1, 2).copy()\n","\n","    # Package data into a dictionary\n","    return {\n","        \"X_train\": X_train,\n","        \"y_train\": y_train,\n","        \"X_val\": X_val,\n","        \"y_val\": y_val,\n","        \"X_test\": X_test,\n","        \"y_test\": y_test,\n","    }\n","\n","\n","def load_tiny_imagenet(path, dtype=np.float32, subtract_mean=True):\n","    \"\"\"\n","    Load TinyImageNet. Each of TinyImageNet-100-A, TinyImageNet-100-B, and\n","    TinyImageNet-200 have the same directory structure, so this can be used\n","    to load any of them.\n","\n","    Inputs:\n","    - path: String giving path to the directory to load.\n","    - dtype: numpy datatype used to load the data.\n","    - subtract_mean: Whether to subtract the mean training image.\n","\n","    Returns: A dictionary with the following entries:\n","    - class_names: A list where class_names[i] is a list of strings giving the\n","      WordNet names for class i in the loaded dataset.\n","    - X_train: (N_tr, 3, 64, 64) array of training images\n","    - y_train: (N_tr,) array of training labels\n","    - X_val: (N_val, 3, 64, 64) array of validation images\n","    - y_val: (N_val,) array of validation labels\n","    - X_test: (N_test, 3, 64, 64) array of testing images.\n","    - y_test: (N_test,) array of test labels; if test labels are not available\n","      (such as in student code) then y_test will be None.\n","    - mean_image: (3, 64, 64) array giving mean training image\n","    \"\"\"\n","    # First load wnids\n","    with open(os.path.join(path, \"wnids.txt\"), \"r\") as f:\n","        wnids = [x.strip() for x in f]\n","\n","    # Map wnids to integer labels\n","    wnid_to_label = {wnid: i for i, wnid in enumerate(wnids)}\n","\n","    # Use words.txt to get names for each class\n","    with open(os.path.join(path, \"words.txt\"), \"r\") as f:\n","        wnid_to_words = dict(line.split(\"\\t\") for line in f)\n","        for wnid, words in wnid_to_words.items():\n","            wnid_to_words[wnid] = [w.strip() for w in words.split(\",\")]\n","    class_names = [wnid_to_words[wnid] for wnid in wnids]\n","\n","    # Next load training data.\n","    X_train = []\n","    y_train = []\n","    for i, wnid in enumerate(wnids):\n","        if (i + 1) % 20 == 0:\n","            print(\"loading training data for synset %d / %d\" % (i + 1, len(wnids)))\n","        # To figure out the filenames we need to open the boxes file\n","        boxes_file = os.path.join(path, \"train\", wnid, \"%s_boxes.txt\" % wnid)\n","        with open(boxes_file, \"r\") as f:\n","            filenames = [x.split(\"\\t\")[0] for x in f]\n","        num_images = len(filenames)\n","\n","        X_train_block = np.zeros((num_images, 3, 64, 64), dtype=dtype)\n","        y_train_block = wnid_to_label[wnid] * np.ones(num_images, dtype=np.int64)\n","        for j, img_file in enumerate(filenames):\n","            img_file = os.path.join(path, \"train\", wnid, \"images\", img_file)\n","            img = imread(img_file)\n","            if img.ndim == 2:\n","                ## grayscale file\n","                img.shape = (64, 64, 1)\n","            X_train_block[j] = img.transpose(2, 0, 1)\n","        X_train.append(X_train_block)\n","        y_train.append(y_train_block)\n","\n","    # We need to concatenate all training data\n","    X_train = np.concatenate(X_train, axis=0)\n","    y_train = np.concatenate(y_train, axis=0)\n","\n","    # Next load validation data\n","    with open(os.path.join(path, \"val\", \"val_annotations.txt\"), \"r\") as f:\n","        img_files = []\n","        val_wnids = []\n","        for line in f:\n","            img_file, wnid = line.split(\"\\t\")[:2]\n","            img_files.append(img_file)\n","            val_wnids.append(wnid)\n","        num_val = len(img_files)\n","        y_val = np.array([wnid_to_label[wnid] for wnid in val_wnids])\n","        X_val = np.zeros((num_val, 3, 64, 64), dtype=dtype)\n","        for i, img_file in enumerate(img_files):\n","            img_file = os.path.join(path, \"val\", \"images\", img_file)\n","            img = imread(img_file)\n","            if img.ndim == 2:\n","                img.shape = (64, 64, 1)\n","            X_val[i] = img.transpose(2, 0, 1)\n","\n","    # Next load test images\n","    # Students won't have test labels, so we need to iterate over files in the\n","    # images directory.\n","    img_files = os.listdir(os.path.join(path, \"test\", \"images\"))\n","    X_test = np.zeros((len(img_files), 3, 64, 64), dtype=dtype)\n","    for i, img_file in enumerate(img_files):\n","        img_file = os.path.join(path, \"test\", \"images\", img_file)\n","        img = imread(img_file)\n","        if img.ndim == 2:\n","            img.shape = (64, 64, 1)\n","        X_test[i] = img.transpose(2, 0, 1)\n","\n","    y_test = None\n","    y_test_file = os.path.join(path, \"test\", \"test_annotations.txt\")\n","    if os.path.isfile(y_test_file):\n","        with open(y_test_file, \"r\") as f:\n","            img_file_to_wnid = {}\n","            for line in f:\n","                line = line.split(\"\\t\")\n","                img_file_to_wnid[line[0]] = line[1]\n","        y_test = [wnid_to_label[img_file_to_wnid[img_file]] for img_file in img_files]\n","        y_test = np.array(y_test)\n","\n","    mean_image = X_train.mean(axis=0)\n","    if subtract_mean:\n","        X_train -= mean_image[None]\n","        X_val -= mean_image[None]\n","        X_test -= mean_image[None]\n","\n","    return {\n","        \"class_names\": class_names,\n","        \"X_train\": X_train,\n","        \"y_train\": y_train,\n","        \"X_val\": X_val,\n","        \"y_val\": y_val,\n","        \"X_test\": X_test,\n","        \"y_test\": y_test,\n","        \"class_names\": class_names,\n","        \"mean_image\": mean_image,\n","    }\n","\n","\n","def load_models(models_dir):\n","    \"\"\"\n","    Load saved models from disk. This will attempt to unpickle all files in a\n","    directory; any files that give errors on unpickling (such as README.txt)\n","    will be skipped.\n","\n","    Inputs:\n","    - models_dir: String giving the path to a directory containing model files.\n","      Each model file is a pickled dictionary with a 'model' field.\n","\n","    Returns:\n","    A dictionary mapping model file names to models.\n","    \"\"\"\n","    models = {}\n","    for model_file in os.listdir(models_dir):\n","        with open(os.path.join(models_dir, model_file), \"rb\") as f:\n","            try:\n","                models[model_file] = load_pickle(f)[\"model\"]\n","            except pickle.UnpicklingError:\n","                continue\n","    return models\n","\n","\n","def load_imagenet_val(num=None):\n","    \"\"\"Load a handful of validation images from ImageNet.\n","\n","    Inputs:\n","    - num: Number of images to load (max of 25)\n","\n","    Returns:\n","    - X: numpy array with shape [num, 224, 224, 3]\n","    - y: numpy array of integer image labels, shape [num]\n","    - class_names: dict mapping integer label to class name\n","    \"\"\"\n","    imagenet_fn = os.path.join(\n","        os.path.dirname(__file__), \"datasets/imagenet_val_25.npz\"\n","    )\n","    if not os.path.isfile(imagenet_fn):\n","        print(\"file %s not found\" % imagenet_fn)\n","        print(\"Run the following:\")\n","        print(\"cd cs231n/datasets\")\n","        print(\"bash get_imagenet_val.sh\")\n","        assert False, \"Need to download imagenet_val_25.npz\"\n","\n","    # modify the default parameters of np.load\n","    # https://stackoverflow.com/questions/55890813/how-to-fix-object-arrays-cannot-be-loaded-when-allow-pickle-false-for-imdb-loa\n","    np_load_old = np.load\n","    np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n","    f = np.load(imagenet_fn)\n","    np.load = np_load_old\n","    X = f[\"X\"]\n","    y = f[\"y\"]\n","    class_names = f[\"label_map\"].item()\n","    if num is not None:\n","        X = X[:num]\n","        y = y[:num]\n","    return X, y, class_names\n"],"metadata":{"id":"EwY6HGF4sq3Q","executionInfo":{"status":"ok","timestamp":1643027351828,"user_tz":-420,"elapsed":1188,"user":{"displayName":"Phạm Đức Thể","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0DbvnWDzLWfReqJkA_CpifKsPoGK79L7Ow3Jg1w=s64","userId":"09005724978234100310"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["## data shallow"],"metadata":{"id":"WzmG6wLGs6vn"}},{"cell_type":"code","source":["def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000):\n","\n","    # Load the raw CIFAR-10 data\n","    cifar10_dir = '/content/drive/MyDrive/TÀI LIỆU HỌC TẬP ĐẠI HỌC 2019-2023/PYTHON & ML 02/BUỔI 12 29 05 2021/data/cifar-10-batches-py'\n","\n","    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n","\n","    # Subsample the data\n","    mask = list(range(num_training, num_training + num_validation))\n","    X_val = X_train[mask]\n","    y_val = y_train[mask]\n","    mask = list(range(num_training))\n","    X_train = X_train[mask]\n","    y_train = y_train[mask]\n","    mask = list(range(num_test))\n","    X_test = X_test[mask]\n","    y_test = y_test[mask]\n","\n","    # Normalize the data: subtract the mean image\n","    mean_image = np.mean(X_train, axis=0)\n","    X_train -= mean_image\n","    X_val -= mean_image\n","    X_test -= mean_image\n","\n","    # Reshape data to rows\n","    X_train = X_train.reshape(num_training, -1)\n","    X_val = X_val.reshape(num_validation, -1)\n","    X_test = X_test.reshape(num_test, -1)\n","\n","    return X_train, y_train, X_val, y_val, X_test, y_test"],"metadata":{"id":"us9OJx7Ds-2y","executionInfo":{"status":"ok","timestamp":1643027352447,"user_tz":-420,"elapsed":6,"user":{"displayName":"Phạm Đức Thể","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0DbvnWDzLWfReqJkA_CpifKsPoGK79L7Ow3Jg1w=s64","userId":"09005724978234100310"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["## Layers"],"metadata":{"id":"pZHtozzDtcy6"}},{"cell_type":"code","source":["def softmax_loss(x, y):\n","    N = x.shape[0]\n","    scores = x - np.max(x, axis=1, keepdims=True)\n","    sum_exp = np.exp(scores).sum(axis=1, keepdims=True)\n","    softmax_matrix = np.exp(scores)/sum_exp\n","\n","    loss = np.sum(-np.log(softmax_matrix[np.arange(N), y])) / N\n","    dx = softmax_matrix.copy()\n","    dx[np.arange(N), y] -= 1\n","    dx /= N\n","    return loss, dx\n","\n","\n","def linear_forward(X, W, b):\n","    \"\"\"\n","    X: shape (N, d_1, d_2, ..., d_k)\n","    W: weights, of shape (D, M)\n","    b: biases, of shape (M, )\n","    \"\"\"\n","    X_reshaped = X.reshape(X.shape[0], -1)\n","    Z = X_reshaped @ W + b\n","    cache = (X, W, b)\n","    return Z, cache\n","\n","\n","def linear_backward(dout, cache):\n","    \"\"\"\n","    dout: Upstream of derivative, of shape (N, M)\n","    cache: tuple of X, W, b\n","    \"\"\"\n","    X, W, b = cache\n","    N = X.shape[0]\n","    X_reshaped = X.reshape(N, -1)\n","    dx = dout @ (W.T)\n","    dx = dx.reshape(X.shape)\n","    # weight gradient\n","    dw = X_reshaped.T @ dout\n","    # bias gradient\n","    db = dout.sum(axis=0)\n","\n","    return dx, dw, db\n","\n","\n","def relu_forward(x):\n","    A = np.maximum(0, x)\n","    cache = x\n","    return A, cache\n","\n","\n","def relu_backward(dout, cache):\n","    x = cache\n","    dx = dout * (x > 0)\n","    return dx"],"metadata":{"id":"o7fY6hiitRre","executionInfo":{"status":"ok","timestamp":1643023090594,"user_tz":-420,"elapsed":41,"user":{"displayName":"Phạm Đức Thể","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0DbvnWDzLWfReqJkA_CpifKsPoGK79L7Ow3Jg1w=s64","userId":"09005724978234100310"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Gradient Descent"],"metadata":{"id":"KOdCoAmotpv1"}},{"cell_type":"code","source":["true_w = np.array([1, 2, 3, 4, 5])\n","D = len(true_w)\n","points = []\n","for i in range(500000):\n","    x = np.random.rand(D)\n","    y = true_w.dot(x) + np.random.randn()\n","    points.append((x, y))\n","\n","\n","def Loss(w):\n","    return sum((w.dot(x) - y) ** 2 for x, y in points) / len(points)\n","\n","\n","def dLoss_w(w):\n","    return sum(2 * (w.dot(x) - y) * x for x, y in points) / len(points)\n","\n","def Gradient_Descent(Loss, dLoss_w, D):\n","    w = np.zeros(D)\n","    lr = 0.01\n","    for i in range(1000):\n","        loss = Loss(w)\n","        gradient = dLoss_w(w)\n","        w = w - lr * gradient\n","        print(\"Iterations {}: w = {}, L(w) = {}\".format(i, w, loss))\n","\n","def sLoss(w, i):\n","    x, y = points[i]\n","    return (w.dot(x) - y) ** 2\n","\n","\n","def sdLoss_w(w, i):\n","    x, y = points[i]\n","    return 2 * (w.dot(x) - y) * x\n","\n","def sGradientDescent(sLoss, sdLoss_w, d, num_points):\n","    w = np.zeros(d)\n","    numUpdates = 0\n","    for t in range(1000):\n","        for i in range(num_points):\n","            loss = sLoss(w, i)\n","            gradient = sdLoss_w(w, i)\n","            numUpdates += 1\n","            lr = 1 / numUpdates\n","            w = w - lr * gradient\n","        print(\"Iterations {}: w: {}, sL(w) = {}\".format(t, w, loss))\n","# Gradient_Descent(Loss, dLoss_w, D)\n","sGradientDescent(sLoss, sdLoss_w, D, len(points))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AM3QpFTVtRxJ","executionInfo":{"status":"ok","timestamp":1643026171819,"user_tz":-420,"elapsed":3081262,"user":{"displayName":"Phạm Đức Thể","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0DbvnWDzLWfReqJkA_CpifKsPoGK79L7Ow3Jg1w=s64","userId":"09005724978234100310"}},"outputId":"ebd4dd12-3a9c-4e36-d22b-b5354fac4c41"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Iterations 0: w: [0.49439437 4.2574878  2.34088069 2.58621383 5.31748099], sL(w) = 0.442892957348344\n","Iterations 1: w: [0.55009804 4.0123592  2.41295821 2.74050237 5.28255454], sL(w) = 0.47914772833647595\n","Iterations 2: w: [0.57972814 3.88144031 2.45135224 2.82273284 5.26380948], sL(w) = 0.49871407919697136\n","Iterations 3: w: [0.59953777 3.79373465 2.47704853 2.87777076 5.25123144], sL(w) = 0.5119297268004185\n","Iterations 4: w: [0.61424731 3.72852396 2.49614515 2.91867048 5.24187281], sL(w) = 0.5218194536881706\n","Iterations 5: w: [0.62585776 3.67700353 2.51122869 2.95097209 5.23447639], sL(w) = 0.5296743066139068\n","Iterations 6: w: [0.63539726 3.63464173 2.52362897 2.97752453 5.22839381], sL(w) = 0.5361615755381351\n","Iterations 7: w: [0.64346123 3.59881109 2.53411645 2.99997865 5.22324869], sL(w) = 0.5416696573069244\n","Iterations 8: w: [0.65042403 3.56785798 2.5431758  3.01937298 5.21880392], sL(w) = 0.5464438559129813\n","Iterations 9: w: [0.65653568 3.54067712 2.55113084 3.03640143 5.21490093], sL(w) = 0.5506486569814341\n","Iterations 10: w: [0.66197109 3.51649485 2.55820818 3.05154959 5.21142869], sL(w) = 0.554399529799125\n","Iterations 11: w: [0.66685716 3.49474949 2.5645723  3.0651699  5.20830655], sL(w) = 0.557780530938133\n","Iterations 12: w: [0.67128877 3.47502096 2.57034619 3.0775259  5.20547419], sL(w) = 0.5608546806132402\n","Iterations 13: w: [0.67533859 3.45698728 2.5756241  3.08881958 5.20288534], sL(w) = 0.5636703957545589\n","Iterations 14: w: [0.67906349 3.44039644 2.58047981 3.09920897 5.20050381], sL(w) = 0.5662656474334483\n","Iterations 15: w: [0.68250876 3.42504772 2.58497207 3.10881996 5.19830077], sL(w) = 0.5686707427075677\n","Iterations 16: w: [0.68571101 3.41077875 2.58914838 3.11775434 5.19625287], sL(w) = 0.5709102418980976\n","Iterations 17: w: [0.68870024 3.39745643 2.59304771 3.12609558 5.19434099], sL(w) = 0.5730043140808613\n","Iterations 18: w: [0.69150134 3.38497036 2.59670236 3.13391287 5.19254927], sL(w) = 0.5749697168827496\n","Iterations 19: w: [0.69413516 3.37322799 2.60013941 3.14126425 5.1908644 ], sL(w) = 0.5768205186495267\n","Iterations 20: w: [0.69661935 3.36215101 2.60338177 3.14819877 5.18927514], sL(w) = 0.5785686399818755\n","Iterations 21: w: [0.69896894 3.35167264 2.60644899 3.15475832 5.18777188], sL(w) = 0.5802242661284734\n","Iterations 22: w: [0.70119688 3.34173542 2.60935787 3.16097888 5.18634636], sL(w) = 0.5817961653960473\n","Iterations 23: w: [0.70331435 3.33228964 2.61212296 3.16689163 5.18499145], sL(w) = 0.5832919380860294\n","Iterations 24: w: [0.70533112 3.32329198 2.61475694 3.1725237  5.18370091], sL(w) = 0.5847182133288532\n","Iterations 25: w: [0.70725572 3.31470449 2.6172709  3.17789887 5.18246929], sL(w) = 0.5860808063372797\n","Iterations 26: w: [0.70909567 3.30649375 2.61967463 3.18303809 5.18129179], sL(w) = 0.5873848452314053\n","Iterations 27: w: [0.71085764 3.29863015 2.62197679 3.1879599  5.18016415], sL(w) = 0.588634874210931\n","Iterations 28: w: [0.71254754 3.29108739 2.62418507 3.19268079 5.1790826 ], sL(w) = 0.5898349381646935\n","Iterations 29: w: [0.71417066 3.28384197 2.62630635 3.19721547 5.17804375], sL(w) = 0.5909886525713798\n","Iterations 30: w: [0.71573173 3.27687282 2.62834679 3.20157715 5.17704458], sL(w) = 0.5920992616449345\n","Iterations 31: w: [0.71723502 3.27016101 2.63031194 3.20577769 5.17608237], sL(w) = 0.5931696870138694\n","Iterations 32: w: [0.71868438 3.2636894  2.63220679 3.20982781 5.17515465], sL(w) = 0.5942025687188215\n","Iterations 33: w: [0.72008329 3.25744252 2.63403589 3.21373722 5.1742592 ], sL(w) = 0.5952002999305068\n","Iterations 34: w: [0.72143492 3.25140629 2.63580335 3.21751474 5.173394  ], sL(w) = 0.5961650565104116\n","Iterations 35: w: [0.72274214 3.24556787 2.63751293 3.2211684  5.17255721], sL(w) = 0.5970988222957209\n","Iterations 36: w: [0.72400759 3.23991556 2.63916804 3.22470553 5.17174714], sL(w) = 0.5980034108339793\n","Iterations 37: w: [0.72523369 3.23443863 2.64077184 3.22813286 5.17096224], sL(w) = 0.5988804841430355\n","Iterations 38: w: [0.72642264 3.22912723 2.64232719 3.23145655 5.17020111], sL(w) = 0.599731568971662\n","Iterations 39: w: [0.72757648 3.2239723  2.64383676 3.23468227 5.16946245], sL(w) = 0.6005580709475034\n","Iterations 40: w: [0.72869708 3.2189655  2.64530298 3.23781527 5.16874505], sL(w) = 0.601361286935629\n","Iterations 41: w: [0.72978619 3.21409909 2.64672812 3.24086036 5.1680478 ], sL(w) = 0.6021424158663425\n","Iterations 42: w: [0.7308454  3.20936595 2.64811425 3.24382202 5.16736969], sL(w) = 0.6029025682560909\n","Iterations 43: w: [0.73187621 3.20475945 2.64946332 3.24670441 5.16670975], sL(w) = 0.6036427746074968\n","Iterations 44: w: [0.73287999 3.20027343 2.65077714 3.24951137 5.1660671 ], sL(w) = 0.6043639928393207\n","Iterations 45: w: [0.73385803 3.19590218 2.65205736 3.25224649 5.16544093], sL(w) = 0.60506711487862\n","Iterations 46: w: [0.73481154 3.19164034 2.65330557 3.25491311 5.16483046], sL(w) = 0.6057529725254184\n","Iterations 47: w: [0.73574162 3.18748295 2.65452321 3.25751435 5.16423498], sL(w) = 0.6064223426853483\n","Iterations 48: w: [0.73664932 3.18342534 2.65571164 3.26005313 5.16365382], sL(w) = 0.6070759520463027\n","Iterations 49: w: [0.73753563 3.17946316 2.65687215 3.26253217 5.16308636], sL(w) = 0.6077144812711359\n","Iterations 50: w: [0.73840146 3.17559231 2.65800592 3.26495404 5.162532  ], sL(w) = 0.608338568765782\n","Iterations 51: w: [0.73924767 3.17180897 2.65911408 3.26732113 5.1619902 ], sL(w) = 0.6089488140707591\n","Iterations 52: w: [0.74007507 3.16810953 2.66019769 3.26963571 5.16146044], sL(w) = 0.6095457809194893\n","Iterations 53: w: [0.74088443 3.1644906  2.66125773 3.2718999  5.16094223], sL(w) = 0.6101300000069196\n","Iterations 54: w: [0.74167645 3.16094897 2.66229515 3.2741157  5.16043511], sL(w) = 0.6107019714937852\n","Iterations 55: w: [0.74245182 3.15748165 2.66331081 3.27628498 5.15993865], sL(w) = 0.6112621672825225\n","Iterations 56: w: [0.74321117 3.15408578 2.66430557 3.27840955 5.15945244], sL(w) = 0.6118110330825599\n","Iterations 57: w: [0.74395512 3.15075868 2.66528019 3.28049107 5.1589761 ], sL(w) = 0.6123489902957342\n","Iterations 58: w: [0.74468422 3.1474978  2.66623543 3.28253114 5.15850926], sL(w) = 0.6128764377327348\n","Iterations 59: w: [0.74539901 3.14430074 2.66717199 3.28453128 5.15805157], sL(w) = 0.6133937531834479\n","Iterations 60: w: [0.74610002 3.14116522 2.66809054 3.28649289 5.15760271], sL(w) = 0.6139012948537244\n","Iterations 61: w: [0.74678773 3.13808906 2.66899171 3.28841735 5.15716237], sL(w) = 0.6143994026799116\n","Iterations 62: w: [0.74746259 3.13507022 2.66987611 3.29030593 5.15673025], sL(w) = 0.6148883995406227\n","Iterations 63: w: [0.74812505 3.13210674 2.67074429 3.29215987 5.15630607], sL(w) = 0.6153685923652508\n","Iterations 64: w: [0.74877551 3.12919677 2.67159682 3.29398032 5.15588956], sL(w) = 0.6158402731569461\n","Iterations 65: w: [0.74941439 3.12633854 2.6724342  3.29576838 5.15548048], sL(w) = 0.6163037199347646\n","Iterations 66: w: [0.75004206 3.12353036 2.67325692 3.29752512 5.15507857], sL(w) = 0.6167591976034383\n","Iterations 67: w: [0.75065887 3.12077064 2.67406547 3.29925154 5.15468361], sL(w) = 0.6172069587564812\n","Iterations 68: w: [0.75126516 3.11805783 2.67486027 3.30094859 5.15429539], sL(w) = 0.6176472444198107\n","Iterations 69: w: [0.75186128 3.11539049 2.67564177 3.30261719 5.15391368], sL(w) = 0.6180802847393505\n","Iterations 70: w: [0.75244752 3.11276721 2.67641037 3.30425821 5.15353829], sL(w) = 0.6185062996203099\n","Iterations 71: w: [0.7530242  3.11018667 2.67716646 3.30587249 5.15316902], sL(w) = 0.6189254993176033\n","Iterations 72: w: [0.75359158 3.10764758 2.67791041 3.30746083 5.15280571], sL(w) = 0.6193380849885921\n","Iterations 73: w: [0.75414996 3.10514873 2.67864258 3.30902399 5.15244816], sL(w) = 0.6197442492029211\n","Iterations 74: w: [0.75469959 3.10268894 2.67936332 3.31056269 5.15209621], sL(w) = 0.6201441764211045\n","Iterations 75: w: [0.75524072 3.1002671  2.68007295 3.31207765 5.15174971], sL(w) = 0.6205380434380433\n","Iterations 76: w: [0.75577359 3.09788214 2.68077178 3.31356953 5.15140849], sL(w) = 0.6209260197964074\n","Iterations 77: w: [0.75629843 3.09553302 2.68146011 3.31503899 5.15107241], sL(w) = 0.6213082681744222\n","Iterations 78: w: [0.75681547 3.09321876 2.68213824 3.31648662 5.15074133], sL(w) = 0.621684944747936\n","Iterations 79: w: [0.75732491 3.09093841 2.68280644 3.31791304 5.15041511], sL(w) = 0.6220561995291384\n","Iterations 80: w: [0.75782697 3.08869106 2.68346499 3.31931881 5.15009362], sL(w) = 0.6224221766816139\n","Iterations 81: w: [0.75832184 3.08647583 2.68411412 3.32070448 5.14977673], sL(w) = 0.622783014818259\n","Iterations 82: w: [0.7588097  3.08429187 2.6847541  3.32207057 5.14946433], sL(w) = 0.6231388472792344\n","Iterations 83: w: [0.75929074 3.08213839 2.68538516 3.3234176  5.1491563 ], sL(w) = 0.623489802393825\n","Iterations 84: w: [0.75976513 3.08001459 2.68600753 3.32474606 5.14885252], sL(w) = 0.6238360037248827\n","Iterations 85: w: [0.76023305 3.07791972 2.68662143 3.3260564  5.14855289], sL(w) = 0.6241775702996685\n","Iterations 86: w: [0.76069465 3.07585307 2.68722706 3.32734909 5.1482573 ], sL(w) = 0.6245146168270022\n","Iterations 87: w: [0.76115009 3.07381394 2.68782464 3.32862457 5.14796566], sL(w) = 0.6248472539012444\n","Iterations 88: w: [0.76159952 3.07180164 2.68841436 3.32988324 5.14767787], sL(w) = 0.6251755881948072\n","Iterations 89: w: [0.76204309 3.06981554 2.68899641 3.33112553 5.14739383], sL(w) = 0.6254997226392163\n","Iterations 90: w: [0.76248094 3.06785501 2.68957097 3.33235182 5.14711345], sL(w) = 0.6258197565962239\n","Iterations 91: w: [0.7629132  3.06591944 2.69013822 3.33356249 5.14683665], sL(w) = 0.6261357860185743\n","Iterations 92: w: [0.76334    3.06400824 2.69069834 3.33475791 5.14656334], sL(w) = 0.6264479036036208\n","Iterations 93: w: [0.76376148 3.06212086 2.69125148 3.33593843 5.14629345], sL(w) = 0.6267561989370364\n","Iterations 94: w: [0.76417774 3.06025675 2.69179781 3.33710438 5.14602689], sL(w) = 0.6270607586284613\n","Iterations 95: w: [0.76458892 3.05841537 2.69233748 3.33825611 5.14576359], sL(w) = 0.6273616664406532\n","Iterations 96: w: [0.76499512 3.05659623 2.69287064 3.33939393 5.14550348], sL(w) = 0.6276590034116862\n","Iterations 97: w: [0.76539646 3.05479883 2.69339744 3.34051814 5.14524648], sL(w) = 0.627952847970466\n","Iterations 98: w: [0.76579304 3.05302268 2.69391801 3.34162905 5.14499253], sL(w) = 0.6282432760467366\n","Iterations 99: w: [0.76618496 3.05126734 2.69443249 3.34272695 5.14474156], sL(w) = 0.6285303611750356\n","Iterations 100: w: [0.76657233 3.04953234 2.69494101 3.34381212 5.1444935 ], sL(w) = 0.6288141745920042\n","Iterations 101: w: [0.76695525 3.04781726 2.6954437  3.34488483 5.1442483 ], sL(w) = 0.6290947853308914\n","Iterations 102: w: [0.7673338  3.04612167 2.69594068 3.34594534 5.14400589], sL(w) = 0.6293722603114911\n","Iterations 103: w: [0.76770808 3.04444517 2.69643207 3.3469939  5.14376622], sL(w) = 0.6296466644235177\n","Iterations 104: w: [0.76807818 3.04278736 2.69691799 3.34803077 5.14352922], sL(w) = 0.6299180606067128\n","Iterations 105: w: [0.76844418 3.04114786 2.69739854 3.34905618 5.14329485], sL(w) = 0.6301865099282543\n","Iterations 106: w: [0.76880617 3.0395263  2.69787385 3.35007038 5.14306304], sL(w) = 0.6304520716550016\n","Iterations 107: w: [0.76916423 3.03792232 2.698344   3.35107357 5.14283376], sL(w) = 0.6307148033229683\n","Iterations 108: w: [0.76951844 3.03633555 2.69880911 3.35206599 5.14260694], sL(w) = 0.630974760802898\n","Iterations 109: w: [0.76986886 3.03476568 2.69926928 3.35304784 5.14238254], sL(w) = 0.6312319983633836\n","Iterations 110: w: [0.77021559 3.03321235 2.6997246  3.35401934 5.14216051], sL(w) = 0.6314865687321195\n","Iterations 111: w: [0.77055868 3.03167526 2.70017516 3.35498068 5.14194081], sL(w) = 0.6317385231505933\n","Iterations 112: w: [0.77089821 3.03015409 2.70062106 3.35593206 5.14172339], sL(w) = 0.6319879114311255\n","Iterations 113: w: [0.77123425 3.02864853 2.70106239 3.35687367 5.1415082 ], sL(w) = 0.6322347820070128\n","Iterations 114: w: [0.77156686 3.0271583  2.70149923 3.35780569 5.14129521], sL(w) = 0.6324791819848007\n","Iterations 115: w: [0.77189611 3.0256831  2.70193167 3.35872831 5.14108438], sL(w) = 0.6327211571891701\n","Iterations 116: w: [0.77222205 3.02422265 2.70235979 3.3596417  5.14087565], sL(w) = 0.632960752209572\n","Iterations 117: w: [0.77254476 3.02277669 2.70278366 3.36054602 5.140669  ], sL(w) = 0.6331980104449222\n","Iterations 118: w: [0.77286429 3.02134495 2.70320337 3.36144145 5.14046439], sL(w) = 0.6334329741430009\n","Iterations 119: w: [0.77318069 3.01992716 2.703619   3.36232815 5.14026178], sL(w) = 0.6336656844421394\n","Iterations 120: w: [0.77349403 3.01852309 2.7040306  3.36320627 5.14006113], sL(w) = 0.633896181408243\n","Iterations 121: w: [0.77380436 3.01713248 2.70443827 3.36407596 5.13986241], sL(w) = 0.6341245040717551\n","Iterations 122: w: [0.77411173 3.0157551  2.70484206 3.36493737 5.13966558], sL(w) = 0.6343506904629176\n","Iterations 123: w: [0.77441619 3.01439072 2.70524204 3.36579066 5.13947062], sL(w) = 0.6345747776437066\n","Iterations 124: w: [0.77471779 3.01303911 2.70563828 3.36663596 5.13927748], sL(w) = 0.6347968017426205\n","Iterations 125: w: [0.77501659 3.01170004 2.70603085 3.3674734  5.13908614], sL(w) = 0.6350167979837087\n","Iterations 126: w: [0.77531263 3.01037331 2.7064198  3.36830313 5.13889657], sL(w) = 0.6352348007160746\n","Iterations 127: w: [0.77560596 3.00905871 2.7068052  3.36912527 5.13870874], sL(w) = 0.6354508434431076\n","Iterations 128: w: [0.77589663 3.00775603 2.70718711 3.36993996 5.13852261], sL(w) = 0.6356649588496148\n","Iterations 129: w: [0.77618467 3.00646507 2.70756559 3.37074731 5.13833816], sL(w) = 0.6358771788267529\n","Iterations 130: w: [0.77647013 3.00518564 2.70794069 3.37154744 5.13815536], sL(w) = 0.6360875344995524\n","Iterations 131: w: [0.77675306 3.00391754 2.70831247 3.37234049 5.13797418], sL(w) = 0.6362960562485143\n","Iterations 132: w: [0.7770335  3.0026606  2.70868098 3.37312656 5.1377946 ], sL(w) = 0.636502773734118\n","Iterations 133: w: [0.77731148 3.00141463 2.70904628 3.37390576 5.1376166 ], sL(w) = 0.6367077159198357\n","Iterations 134: w: [0.77758705 3.00017946 2.70940841 3.37467821 5.13744014], sL(w) = 0.6369109110924812\n","Iterations 135: w: [0.77786024 2.99895491 2.70976744 3.37544401 5.13726519], sL(w) = 0.6371123868829215\n","Iterations 136: w: [0.7781311  2.99774081 2.7101234  3.37620328 5.13709175], sL(w) = 0.637312170285647\n","Iterations 137: w: [0.77839965 2.996537   2.71047635 3.3769561  5.13691978], sL(w) = 0.637510287680146\n","Iterations 138: w: [0.77866594 2.99534332 2.71082633 3.37770259 5.13674926], sL(w) = 0.6377067648459845\n","Iterations 139: w: [0.77893    2.99415962 2.71117339 3.37844285 5.13658017], sL(w) = 0.637901626983075\n","Iterations 140: w: [0.77919187 2.99298573 2.71151758 3.37917696 5.13641248], sL(w) = 0.6380948987279872\n","Iterations 141: w: [0.77945157 2.99182151 2.71185893 3.37990502 5.13624618], sL(w) = 0.6382866041701047\n","Iterations 142: w: [0.77970915 2.99066681 2.71219749 3.38062712 5.13608124], sL(w) = 0.6384767668682878\n","Iterations 143: w: [0.77996463 2.98952148 2.71253331 3.38134336 5.13591764], sL(w) = 0.6386654098649555\n","Iterations 144: w: [0.78021804 2.9883854  2.71286642 3.38205382 5.13575537], sL(w) = 0.638852555701598\n","Iterations 145: w: [0.78046942 2.98725841 2.71319686 3.38275859 5.13559439], sL(w) = 0.6390382264344029\n","Iterations 146: w: [0.7807188  2.98614039 2.71352468 3.38345775 5.1354347 ], sL(w) = 0.6392224436453122\n","Iterations 147: w: [0.7809662  2.9850312  2.71384991 3.38415138 5.13527628], sL(w) = 0.6394052284569202\n","Iterations 148: w: [0.78121166 2.98393072 2.71417259 3.38483957 5.1351191 ], sL(w) = 0.6395866015452447\n","Iterations 149: w: [0.7814552  2.98283882 2.71449276 3.38552239 5.13496315], sL(w) = 0.6397665831517484\n","Iterations 150: w: [0.78169685 2.98175537 2.71481045 3.38619993 5.13480841], sL(w) = 0.6399451930949341\n","Iterations 151: w: [0.78193663 2.98068025 2.7151257  3.38687224 5.13465487], sL(w) = 0.64012245078313\n","Iterations 152: w: [0.78217458 2.97961335 2.71543855 3.38753942 5.13450249], sL(w) = 0.6402983752242333\n","Iterations 153: w: [0.78241072 2.97855455 2.71574902 3.38820153 5.13435128], sL(w) = 0.6404729850371013\n","Iterations 154: w: [0.78264507 2.97750374 2.71605715 3.38885865 5.13420122], sL(w) = 0.6406462984629846\n","Iterations 155: w: [0.78287767 2.9764608  2.71636297 3.38951084 5.13405227], sL(w) = 0.6408183333737141\n","Iterations 156: w: [0.78310852 2.97542563 2.71666652 3.39015817 5.13390445], sL(w) = 0.6409891072826637\n","Iterations 157: w: [0.78333767 2.97439812 2.71696782 3.39080071 5.13375771], sL(w) = 0.6411586373528549\n","Iterations 158: w: [0.78356513 2.97337817 2.71726691 3.39143852 5.13361206], sL(w) = 0.6413269404087384\n","Iterations 159: w: [0.78379092 2.97236567 2.71756382 3.39207167 5.13346748], sL(w) = 0.6414940329423273\n","Iterations 160: w: [0.78401506 2.97136052 2.71785857 3.39270022 5.13332394], sL(w) = 0.6416599311233492\n","Iterations 161: w: [0.78423759 2.97036262 2.7181512  3.39332423 5.13318145], sL(w) = 0.6418246508070717\n","Iterations 162: w: [0.78445852 2.96937188 2.71844173 3.39394377 5.13303998], sL(w) = 0.641988207541361\n","Iterations 163: w: [0.78467787 2.9683882  2.71873019 3.39455889 5.13289952], sL(w) = 0.6421506165760753\n","Iterations 164: w: [0.78489566 2.96741149 2.71901661 3.39516965 5.13276006], sL(w) = 0.6423118928694315\n","Iterations 165: w: [0.78511192 2.96644166 2.71930102 3.39577611 5.13262158], sL(w) = 0.6424720510953839\n","Iterations 166: w: [0.78532665 2.96547862 2.71958343 3.39637832 5.13248408], sL(w) = 0.6426311056521566\n","Iterations 167: w: [0.78553989 2.96452228 2.71986389 3.39697633 5.13234753], sL(w) = 0.6427890706661737\n","Iterations 168: w: [0.78575166 2.96357255 2.7201424  3.39757022 5.13221193], sL(w) = 0.6429459600026096\n","Iterations 169: w: [0.78596196 2.96262936 2.72041901 3.39816001 5.13207726], sL(w) = 0.6431017872678074\n","Iterations 170: w: [0.78617082 2.96169261 2.72069372 3.39874577 5.13194352], sL(w) = 0.6432565658176395\n","Iterations 171: w: [0.78637826 2.96076223 2.72096657 3.39932756 5.13181069], sL(w) = 0.6434103087643661\n","Iterations 172: w: [0.7865843  2.95983813 2.72123757 3.3999054  5.13167875], sL(w) = 0.6435630289804364\n","Iterations 173: w: [0.78678894 2.95892024 2.72150676 3.40047937 5.13154771], sL(w) = 0.6437147391050071\n","Iterations 174: w: [0.78699222 2.95800848 2.72177415 3.4010495  5.13141754], sL(w) = 0.6438654515508226\n","Iterations 175: w: [0.78719415 2.95710278 2.72203977 3.40161584 5.13128824], sL(w) = 0.6440151785067568\n","Iterations 176: w: [0.78739474 2.95620306 2.72230363 3.40217844 5.1311598 ], sL(w) = 0.6441639319460467\n","Iterations 177: w: [0.78759401 2.95530924 2.72256577 3.40273735 5.1310322 ], sL(w) = 0.6443117236294041\n","Iterations 178: w: [0.78779197 2.95442126 2.72282619 3.40329261 5.13090543], sL(w) = 0.6444585651103055\n","Iterations 179: w: [0.78798865 2.95353905 2.72308492 3.40384426 5.13077949], sL(w) = 0.6446044677400693\n","Iterations 180: w: [0.78818405 2.95266253 2.72334199 3.40439234 5.13065437], sL(w) = 0.6447494426732482\n","Iterations 181: w: [0.7883782  2.95179164 2.72359741 3.40493691 5.13053005], sL(w) = 0.644893500869868\n","Iterations 182: w: [0.7885711  2.95092632 2.72385119 3.40547799 5.13040652], sL(w) = 0.6450366531022617\n","Iterations 183: w: [0.78876278 2.95006649 2.72410337 3.40601564 5.13028379], sL(w) = 0.6451789099584303\n","Iterations 184: w: [0.78895324 2.94921209 2.72435395 3.40654989 5.13016183], sL(w) = 0.6453202818448942\n","Iterations 185: w: [0.78914251 2.94836306 2.72460296 3.40708078 5.13004064], sL(w) = 0.6454607789929933\n","Iterations 186: w: [0.78933059 2.94751934 2.72485042 3.40760836 5.1299202 ], sL(w) = 0.6456004114613251\n","Iterations 187: w: [0.78951749 2.94668086 2.72509634 3.40813265 5.12980052], sL(w) = 0.6457391891393318\n","Iterations 188: w: [0.78970324 2.94584756 2.72534074 3.4086537  5.12968158], sL(w) = 0.6458771217528642\n","Iterations 189: w: [0.78988784 2.94501939 2.72558364 3.40917155 5.12956337], sL(w) = 0.6460142188652324\n","Iterations 190: w: [0.79007131 2.94419629 2.72582506 3.40968622 5.12944589], sL(w) = 0.6461504898828384\n","Iterations 191: w: [0.79025367 2.9433782  2.726065   3.41019776 5.12932912], sL(w) = 0.646285944056694\n","Iterations 192: w: [0.79043491 2.94256506 2.7263035  3.4107062  5.12921307], sL(w) = 0.6464205904874705\n","Iterations 193: w: [0.79061506 2.94175682 2.72654056 3.41121158 5.12909771], sL(w) = 0.6465544381289361\n","Iterations 194: w: [0.79079413 2.94095342 2.7267762  3.41171393 5.12898305], sL(w) = 0.6466874957882228\n","Iterations 195: w: [0.79097213 2.94015481 2.72701044 3.41221329 5.12886907], sL(w) = 0.6468197721323758\n","Iterations 196: w: [0.79114908 2.93936094 2.72724328 3.41270968 5.12875577], sL(w) = 0.6469512756894839\n","Iterations 197: w: [0.79132497 2.93857175 2.72747476 3.41320314 5.12864314], sL(w) = 0.6470820148511507\n","Iterations 198: w: [0.79149983 2.9377872  2.72770488 3.4136937  5.12853117], sL(w) = 0.6472119978774464\n","Iterations 199: w: [0.79167367 2.93700723 2.72793365 3.41418139 5.12841986], sL(w) = 0.6473412328973818\n","Iterations 200: w: [0.79184649 2.9362318  2.7281611  3.41466625 5.12830919], sL(w) = 0.6474697279124813\n","Iterations 201: w: [0.79201831 2.93546085 2.72838723 3.41514831 5.12819917], sL(w) = 0.6475974908008375\n","Iterations 202: w: [0.79218914 2.93469434 2.72861206 3.41562758 5.12808978], sL(w) = 0.6477245293163262\n","Iterations 203: w: [0.79235899 2.93393221 2.72883561 3.41610411 5.12798102], sL(w) = 0.6478508510945332\n","Iterations 204: w: [0.79252787 2.93317444 2.72905788 3.41657793 5.12787289], sL(w) = 0.6479764636526332\n","Iterations 205: w: [0.79269579 2.93242096 2.72927889 3.41704906 5.12776536], sL(w) = 0.6481013743933705\n","Iterations 206: w: [0.79286276 2.93167173 2.72949866 3.41751752 5.12765845], sL(w) = 0.6482255906070775\n","Iterations 207: w: [0.79302879 2.93092671 2.72971719 3.41798335 5.12755213], sL(w) = 0.6483491194734089\n","Iterations 208: w: [0.79319389 2.93018586 2.72993451 3.41844658 5.12744642], sL(w) = 0.6484719680635573\n","Iterations 209: w: [0.79335807 2.92944913 2.73015061 3.41890723 5.12734129], sL(w) = 0.6485941433428082\n","Iterations 210: w: [0.79352134 2.92871648 2.73036552 3.41936533 5.12723675], sL(w) = 0.6487156521722091\n","Iterations 211: w: [0.79368371 2.92798786 2.73057925 3.4198209  5.12713278], sL(w) = 0.6488365013116514\n","Iterations 212: w: [0.79384518 2.92726325 2.7307918  3.42027398 5.12702938], sL(w) = 0.6489566974197848\n","Iterations 213: w: [0.79400577 2.92654258 2.7310032  3.42072458 5.12692655], sL(w) = 0.6490762470587295\n","Iterations 214: w: [0.79416549 2.92582584 2.73121345 3.42117273 5.12682428], sL(w) = 0.649195156693063\n","Iterations 215: w: [0.79432434 2.92511297 2.73142256 3.42161845 5.12672257], sL(w) = 0.6493134326936643\n","Iterations 216: w: [0.79448233 2.92440394 2.73163055 3.42206178 5.1266214 ], sL(w) = 0.6494310813389185\n","Iterations 217: w: [0.79463948 2.92369871 2.73183742 3.42250272 5.12652078], sL(w) = 0.6495481088169043\n","Iterations 218: w: [0.79479578 2.92299724 2.73204319 3.42294132 5.1264207 ], sL(w) = 0.6496645212254314\n","Iterations 219: w: [0.79495126 2.9222995  2.73224787 3.42337758 5.12632115], sL(w) = 0.6497803245770745\n","Iterations 220: w: [0.7951059  2.92160544 2.73245147 3.42381154 5.12622212], sL(w) = 0.6498955247965724\n","Iterations 221: w: [0.79525974 2.92091504 2.732654   3.42424321 5.12612362], sL(w) = 0.6500101277252639\n","Iterations 222: w: [0.79541276 2.92022825 2.73285546 3.42467263 5.12602563], sL(w) = 0.6501241391227103\n","Iterations 223: w: [0.79556499 2.91954505 2.73305588 3.4250998  5.12592816], sL(w) = 0.6502375646662274\n","Iterations 224: w: [0.79571642 2.91886539 2.73325526 3.42552475 5.1258312 ], sL(w) = 0.6503504099547903\n","Iterations 225: w: [0.79586707 2.91818925 2.73345361 3.4259475  5.12573473], sL(w) = 0.6504626805087531\n","Iterations 226: w: [0.79601695 2.91751658 2.73365094 3.42636808 5.12563877], sL(w) = 0.6505743817724133\n","Iterations 227: w: [0.79616605 2.91684736 2.73384726 3.4267865  5.12554329], sL(w) = 0.6506855191134385\n","Iterations 228: w: [0.79631439 2.91618156 2.73404258 3.42720279 5.12544831], sL(w) = 0.6507960978270719\n","Iterations 229: w: [0.79646198 2.91551914 2.73423691 3.42761697 5.12535381], sL(w) = 0.650906123135762\n","Iterations 230: w: [0.79660881 2.91486006 2.73443025 3.42802904 5.12525979], sL(w) = 0.6510156001902345\n","Iterations 231: w: [0.79675491 2.91420431 2.73462263 3.42843905 5.12516624], sL(w) = 0.6511245340717762\n","Iterations 232: w: [0.79690027 2.91355184 2.73481404 3.42884699 5.12507316], sL(w) = 0.6512329297925197\n","Iterations 233: w: [0.79704491 2.91290263 2.73500449 3.4292529  5.12498055], sL(w) = 0.6513407922972247\n","Iterations 234: w: [0.79718883 2.91225665 2.735194   3.42965679 5.1248884 ], sL(w) = 0.6514481264647626\n","Iterations 235: w: [0.79733203 2.91161386 2.73538257 3.43005868 5.12479671], sL(w) = 0.6515549371086071\n","Iterations 236: w: [0.79747452 2.91097425 2.73557022 3.43045859 5.12470547], sL(w) = 0.6516612289783915\n","Iterations 237: w: [0.79761631 2.91033777 2.73575694 3.43085654 5.12461468], sL(w) = 0.6517670067605394\n","Iterations 238: w: [0.79775741 2.9097044  2.73594275 3.43125254 5.12452433], sL(w) = 0.6518722750796291\n","Iterations 239: w: [0.79789782 2.90907412 2.73612766 3.43164661 5.12443442], sL(w) = 0.6519770385006971\n","Iterations 240: w: [0.79803755 2.90844689 2.73631168 3.43203877 5.12434496], sL(w) = 0.6520813015272925\n","Iterations 241: w: [0.7981766  2.90782269 2.7364948  3.43242904 5.12425592], sL(w) = 0.6521850686056981\n","Iterations 242: w: [0.79831499 2.90720148 2.73667705 3.43281743 5.12416731], sL(w) = 0.6522883441243166\n","Iterations 243: w: [0.79845271 2.90658326 2.73685842 3.43320396 5.12407913], sL(w) = 0.6523911324145393\n","Iterations 244: w: [0.79858977 2.90596798 2.73703894 3.43358865 5.12399137], sL(w) = 0.6524934377522216\n","Iterations 245: w: [0.79872618 2.90535562 2.73721859 3.43397151 5.12390403], sL(w) = 0.6525952643586294\n","Iterations 246: w: [0.79886194 2.90474615 2.7373974  3.43435256 5.1238171 ], sL(w) = 0.6526966164006134\n","Iterations 247: w: [0.79899706 2.90413956 2.73757536 3.43473181 5.12373058], sL(w) = 0.6527974979929116\n","Iterations 248: w: [0.79913155 2.90353581 2.73775249 3.43510929 5.12364447], sL(w) = 0.6528979131975778\n","Iterations 249: w: [0.7992654  2.90293488 2.7379288  3.435485   5.12355876], sL(w) = 0.6529978660257539\n","Iterations 250: w: [0.79939863 2.90233675 2.73810428 3.43585896 5.12347345], sL(w) = 0.6530973604383408\n","Iterations 251: w: [0.79953125 2.90174139 2.73827895 3.43623119 5.12338854], sL(w) = 0.6531964003463631\n","Iterations 252: w: [0.79966325 2.90114878 2.73845282 3.4366017  5.12330402], sL(w) = 0.6532949896126412\n","Iterations 253: w: [0.79979464 2.9005589  2.73862589 3.4369705  5.12321989], sL(w) = 0.6533931320520913\n","Iterations 254: w: [0.79992543 2.89997172 2.73879816 3.43733762 5.12313615], sL(w) = 0.6534908314316037\n","Iterations 255: w: [0.80005562 2.89938721 2.73896965 3.43770306 5.12305278], sL(w) = 0.6535880914729668\n","Iterations 256: w: [0.80018522 2.89880536 2.73914037 3.43806684 5.1229698 ], sL(w) = 0.6536849158510881\n","Iterations 257: w: [0.80031423 2.89822615 2.73931031 3.43842897 5.1228872 ], sL(w) = 0.6537813081972987\n","Iterations 258: w: [0.80044265 2.89764955 2.73947948 3.43878947 5.12280497], sL(w) = 0.6538772720976954\n","Iterations 259: w: [0.8005705  2.89707553 2.7396479  3.43914834 5.12272311], sL(w) = 0.6539728110956172\n","Iterations 260: w: [0.80069778 2.89650409 2.73981556 3.43950562 5.12264161], sL(w) = 0.654067928691086\n","Iterations 261: w: [0.80082448 2.89593519 2.73998247 3.43986129 5.12256048], sL(w) = 0.6541626283422348\n","Iterations 262: w: [0.80095063 2.89536882 2.74014865 3.44021539 5.12247972], sL(w) = 0.6542569134661314\n","Iterations 263: w: [0.80107621 2.89480496 2.74031409 3.44056792 5.1223993 ], sL(w) = 0.6543507874382988\n","Iterations 264: w: [0.80120124 2.89424358 2.7404788  3.4409189  5.12231925], sL(w) = 0.6544442535956445\n","Iterations 265: w: [0.80132572 2.89368467 2.74064279 3.44126834 5.12223955], sL(w) = 0.6545373152337854\n","Iterations 266: w: [0.80144965 2.8931282  2.74080607 3.44161624 5.12216019], sL(w) = 0.654629975610142\n","Iterations 267: w: [0.80157304 2.89257415 2.74096863 3.44196263 5.12208119], sL(w) = 0.6547222379445822\n","Iterations 268: w: [0.8016959  2.89202251 2.74113049 3.44230752 5.12200252], sL(w) = 0.6548141054180058\n","Iterations 269: w: [0.80181822 2.89147326 2.74129164 3.44265091 5.1219242 ], sL(w) = 0.6549055811751352\n","Iterations 270: w: [0.80194001 2.89092637 2.74145211 3.44299282 5.12184622], sL(w) = 0.6549966683238454\n","Iterations 271: w: [0.80206128 2.89038183 2.74161188 3.44333327 5.12176857], sL(w) = 0.6550873699361658\n","Iterations 272: w: [0.80218204 2.88983962 2.74177098 3.44367226 5.12169125], sL(w) = 0.6551776890477234\n","Iterations 273: w: [0.80230227 2.88929972 2.74192939 3.4440098  5.12161427], sL(w) = 0.655267628660983\n","Iterations 274: w: [0.80242199 2.88876212 2.74208714 3.44434591 5.12153761], sL(w) = 0.6553571917424232\n","Iterations 275: w: [0.80254121 2.88822679 2.74224421 3.44468059 5.12146128], sL(w) = 0.6554463812256808\n","Iterations 276: w: [0.80265992 2.88769371 2.74240063 3.44501387 5.12138527], sL(w) = 0.6555352000105847\n","Iterations 277: w: [0.80277813 2.88716288 2.74255639 3.44534574 5.12130958], sL(w) = 0.6556236509639414\n","Iterations 278: w: [0.80289585 2.88663427 2.7427115  3.44567623 5.12123421], sL(w) = 0.6557117369204727\n","Iterations 279: w: [0.80301307 2.88610786 2.74286596 3.44600533 5.12115915], sL(w) = 0.6557994606829848\n","Iterations 280: w: [0.80312981 2.88558364 2.74301978 3.44633307 5.12108441], sL(w) = 0.6558868250229261\n","Iterations 281: w: [0.80324606 2.88506159 2.74317296 3.44665945 5.12100998], sL(w) = 0.6559738326808099\n","Iterations 282: w: [0.80336183 2.88454169 2.74332551 3.44698448 5.12093585], sL(w) = 0.6560604863660205\n","Iterations 283: w: [0.80347712 2.88402393 2.74347744 3.44730818 5.12086203], sL(w) = 0.656146788759405\n","Iterations 284: w: [0.80359194 2.8835083  2.74362874 3.44763055 5.12078851], sL(w) = 0.656232742510266\n","Iterations 285: w: [0.80370629 2.88299477 2.74377943 3.4479516  5.1207153 ], sL(w) = 0.6563183502397434\n","Iterations 286: w: [0.80382018 2.88248333 2.7439295  3.44827134 5.12064238], sL(w) = 0.656403614540541\n","Iterations 287: w: [0.8039336  2.88197396 2.74407897 3.44858979 5.12056976], sL(w) = 0.6564885379767191\n","Iterations 288: w: [0.80404656 2.88146665 2.74422783 3.44890695 5.12049743], sL(w) = 0.656573123083609\n","Iterations 289: w: [0.80415907 2.88096138 2.74437609 3.44922284 5.12042539], sL(w) = 0.6566573723699446\n","Iterations 290: w: [0.80427112 2.88045814 2.74452376 3.44953745 5.12035365], sL(w) = 0.656741288317001\n","Iterations 291: w: [0.80438272 2.87995691 2.74467084 3.44985081 5.12028219], sL(w) = 0.6568248733796116\n","Iterations 292: w: [0.80449388 2.87945769 2.74481734 3.45016292 5.12021102], sL(w) = 0.6569081299848314\n","Iterations 293: w: [0.8046046  2.87896044 2.74496325 3.45047379 5.12014013], sL(w) = 0.6569910605355135\n","Iterations 294: w: [0.80471488 2.87846516 2.74510859 3.45078342 5.12006952], sL(w) = 0.6570736674084098\n","Iterations 295: w: [0.80482472 2.87797184 2.74525335 3.45109184 5.11999919], sL(w) = 0.6571559529543068\n","Iterations 296: w: [0.80493413 2.87748045 2.74539754 3.45139904 5.11992914], sL(w) = 0.6572379194998269\n","Iterations 297: w: [0.80504311 2.87699099 2.74554117 3.45170504 5.11985936], sL(w) = 0.6573195693460677\n","Iterations 298: w: [0.80515166 2.87650344 2.74568424 3.45200984 5.11978986], sL(w) = 0.6574009047707962\n","Iterations 299: w: [0.80525979 2.87601779 2.74582676 3.45231346 5.11972063], sL(w) = 0.6574819280272733\n","Iterations 300: w: [0.8053675  2.87553403 2.74596872 3.4526159  5.11965166], sL(w) = 0.6575626413456608\n","Iterations 301: w: [0.80547479 2.87505213 2.74611013 3.45291716 5.11958297], sL(w) = 0.657643046932142\n","Iterations 302: w: [0.80558166 2.87457209 2.746251   3.45321727 5.11951454], sL(w) = 0.6577231469705838\n","Iterations 303: w: [0.80568813 2.8740939  2.74639132 3.45351623 5.11944637], sL(w) = 0.6578029436224859\n","Iterations 304: w: [0.80579419 2.87361753 2.74653111 3.45381403 5.11937847], sL(w) = 0.6578824390259925\n","Iterations 305: w: [0.80589984 2.87314299 2.74667037 3.45411071 5.11931082], sL(w) = 0.657961635298503\n","Iterations 306: w: [0.80600509 2.87267024 2.7468091  3.45440625 5.11924343], sL(w) = 0.6580405345346825\n","Iterations 307: w: [0.80610994 2.8721993  2.74694731 3.45470067 5.1191763 ], sL(w) = 0.6581191388079798\n","Iterations 308: w: [0.80621439 2.87173013 2.74708499 3.45499398 5.11910942], sL(w) = 0.6581974501710374\n","Iterations 309: w: [0.80631844 2.87126272 2.74722215 3.45528619 5.1190428 ], sL(w) = 0.6582754706555743\n","Iterations 310: w: [0.80642211 2.87079707 2.7473588  3.45557729 5.11897642], sL(w) = 0.6583532022727722\n","Iterations 311: w: [0.80652539 2.87033317 2.74749494 3.45586731 5.1189103 ], sL(w) = 0.6584306470129822\n","Iterations 312: w: [0.80662828 2.86987099 2.74763057 3.45615625 5.11884442], sL(w) = 0.6585078068468898\n","Iterations 313: w: [0.80673079 2.86941054 2.7477657  3.45644411 5.11877879], sL(w) = 0.6585846837257654\n","Iterations 314: w: [0.80683291 2.86895179 2.74790032 3.4567309  5.1187134 ], sL(w) = 0.6586612795805782\n","Iterations 315: w: [0.80693466 2.86849473 2.74803445 3.45701663 5.11864825], sL(w) = 0.658737596323637\n","Iterations 316: w: [0.80703604 2.86803936 2.74816809 3.45730131 5.11858335], sL(w) = 0.6588136358478437\n","Iterations 317: w: [0.80713704 2.86758566 2.74830123 3.45758495 5.11851868], sL(w) = 0.658889400027926\n","Iterations 318: w: [0.80723767 2.86713362 2.74843389 3.45786754 5.11845425], sL(w) = 0.6589648907201697\n","Iterations 319: w: [0.80733793 2.86668324 2.74856607 3.45814911 5.11839006], sL(w) = 0.6590401097616586\n","Iterations 320: w: [0.80743782 2.86623448 2.74869777 3.45842965 5.1183261 ], sL(w) = 0.6591150589717418\n","Iterations 321: w: [0.80753736 2.86578736 2.74882898 3.45870917 5.11826237], sL(w) = 0.6591897401529329\n","Iterations 322: w: [0.80763653 2.86534185 2.74895973 3.45898768 5.11819887], sL(w) = 0.6592641550891943\n","Iterations 323: w: [0.80773535 2.86489795 2.74909    3.45926519 5.1181356 ], sL(w) = 0.6593383055477631\n","Iterations 324: w: [0.8078338  2.86445564 2.74921981 3.4595417  5.11807256], sL(w) = 0.6594121932774271\n","Iterations 325: w: [0.80793191 2.86401492 2.74934915 3.45981722 5.11800975], sL(w) = 0.6594858200118322\n","Iterations 326: w: [0.80802967 2.86357577 2.74947803 3.46009176 5.11794716], sL(w) = 0.6595591874672058\n","Iterations 327: w: [0.80812707 2.86313818 2.74960645 3.46036532 5.1178848 ], sL(w) = 0.6596322973429505\n","Iterations 328: w: [0.80822413 2.86270215 2.74973442 3.4606379  5.11782265], sL(w) = 0.6597051513220099\n","Iterations 329: w: [0.80832085 2.86226766 2.74986193 3.46090953 5.11776073], sL(w) = 0.6597777510724419\n","Iterations 330: w: [0.80841722 2.8618347  2.749989   3.46118019 5.11769903], sL(w) = 0.6598500982457874\n","Iterations 331: w: [0.80851325 2.86140326 2.75011562 3.4614499  5.11763754], sL(w) = 0.6599221944768522\n","Iterations 332: w: [0.80860895 2.86097334 2.75024179 3.46171867 5.11757627], sL(w) = 0.6599940413869873\n","Iterations 333: w: [0.80870431 2.86054492 2.75036753 3.46198649 5.11751521], sL(w) = 0.6600656405809086\n","Iterations 334: w: [0.80879934 2.86011799 2.75049282 3.46225339 5.11745437], sL(w) = 0.6601369936484918\n","Iterations 335: w: [0.80889404 2.85969255 2.75061769 3.46251935 5.11739374], sL(w) = 0.6602081021647881\n","Iterations 336: w: [0.8089884  2.85926858 2.75074212 3.4627844  5.11733332], sL(w) = 0.6602789676902795\n","Iterations 337: w: [0.80908245 2.85884607 2.75086612 3.46304852 5.11727311], sL(w) = 0.6603495917706501\n","Iterations 338: w: [0.80917616 2.85842502 2.75098969 3.46331174 5.11721311], sL(w) = 0.6604199759371564\n","Iterations 339: w: [0.80926956 2.85800542 2.75111284 3.46357405 5.11715331], sL(w) = 0.6604901217073733\n","Iterations 340: w: [0.80936263 2.85758725 2.75123557 3.46383547 5.11709372], sL(w) = 0.6605600305841968\n","Iterations 341: w: [0.80945539 2.85717051 2.75135788 3.46409599 5.11703433], sL(w) = 0.6606297040571693\n","Iterations 342: w: [0.80954783 2.85675518 2.75147977 3.46435563 5.11697515], sL(w) = 0.6606991436022778\n","Iterations 343: w: [0.80963995 2.85634127 2.75160126 3.46461438 5.11691616], sL(w) = 0.6607683506810875\n","Iterations 344: w: [0.80973177 2.85592876 2.75172233 3.46487226 5.11685738], sL(w) = 0.6608373267429999\n","Iterations 345: w: [0.80982327 2.85551764 2.75184299 3.46512927 5.1167988 ], sL(w) = 0.6609060732231237\n","Iterations 346: w: [0.80991446 2.8551079  2.75196325 3.46538541 5.11674041], sL(w) = 0.6609745915445157\n","Iterations 347: w: [0.81000535 2.85469954 2.7520831  3.46564069 5.11668222], sL(w) = 0.6610428831169284\n","Iterations 348: w: [0.81009593 2.85429254 2.75220255 3.46589512 5.11662422], sL(w) = 0.661110949337466\n","Iterations 349: w: [0.81018621 2.8538869  2.75232161 3.4661487  5.11656642], sL(w) = 0.6611787915903393\n","Iterations 350: w: [0.81027619 2.85348261 2.75244027 3.46640144 5.11650881], sL(w) = 0.6612464112477431\n","Iterations 351: w: [0.81036587 2.85307966 2.75255853 3.46665334 5.11645139], sL(w) = 0.6613138096690457\n","Iterations 352: w: [0.81045525 2.85267805 2.75267641 3.4669044  5.11639417], sL(w) = 0.6613809882022944\n","Iterations 353: w: [0.81054434 2.85227776 2.7527939  3.46715464 5.11633713], sL(w) = 0.6614479481827984\n","Iterations 354: w: [0.81063313 2.85187878 2.752911   3.46740405 5.11628028], sL(w) = 0.6615146909342314\n","Iterations 355: w: [0.81072163 2.85148111 2.75302771 3.46765265 5.11622362], sL(w) = 0.661581217769449\n","Iterations 356: w: [0.81080985 2.85108475 2.75314405 3.46790043 5.11616714], sL(w) = 0.6616475299881432\n","Iterations 357: w: [0.81089777 2.85068967 2.75326001 3.4681474  5.11611085], sL(w) = 0.6617136288797971\n","Iterations 358: w: [0.81098541 2.85029588 2.75337559 3.46839357 5.11605474], sL(w) = 0.6617795157213978\n","Iterations 359: w: [0.81107276 2.84990337 2.7534908  3.46863894 5.11599881], sL(w) = 0.6618451917800917\n","Iterations 360: w: [0.81115983 2.84951213 2.75360563 3.46888352 5.11594307], sL(w) = 0.661910658311521\n","Iterations 361: w: [0.81124661 2.84912214 2.75372009 3.46912731 5.1158875 ], sL(w) = 0.6619759165599798\n","Iterations 362: w: [0.81133312 2.84873342 2.75383419 3.46937031 5.11583211], sL(w) = 0.662040967759273\n","Iterations 363: w: [0.81141935 2.84834594 2.75394792 3.46961254 5.11577691], sL(w) = 0.6621058131322803\n","Iterations 364: w: [0.81150531 2.84795969 2.75406129 3.46985399 5.11572187], sL(w) = 0.6621704538921513\n","Iterations 365: w: [0.81159098 2.84757468 2.75417429 3.47009467 5.11566702], sL(w) = 0.662234891240192\n","Iterations 366: w: [0.81167639 2.8471909  2.75428694 3.47033458 5.11561234], sL(w) = 0.6622991263692181\n","Iterations 367: w: [0.81176152 2.84680833 2.75439923 3.47057373 5.11555783], sL(w) = 0.6623631604595507\n","Iterations 368: w: [0.81184639 2.84642697 2.75451117 3.47081213 5.1155035 ], sL(w) = 0.662426994683865\n","Iterations 369: w: [0.81193098 2.84604682 2.75462275 3.47104977 5.11544934], sL(w) = 0.6624906302030206\n","Iterations 370: w: [0.81201531 2.84566786 2.75473398 3.47128667 5.11539535], sL(w) = 0.6625540681689113\n","Iterations 371: w: [0.81209938 2.84529009 2.75484486 3.47152282 5.11534153], sL(w) = 0.6626173097236037\n","Iterations 372: w: [0.81218318 2.84491351 2.7549554  3.47175823 5.11528787], sL(w) = 0.6626803559991836\n","Iterations 373: w: [0.81226672 2.8445381  2.75506559 3.47199291 5.11523439], sL(w) = 0.6627432081179839\n","Iterations 374: w: [0.81234999 2.84416385 2.75517544 3.47222686 5.11518107], sL(w) = 0.6628058671941243\n","Iterations 375: w: [0.81243301 2.84379077 2.75528495 3.47246008 5.11512792], sL(w) = 0.66286833433111\n","Iterations 376: w: [0.81251577 2.84341885 2.75539412 3.47269257 5.11507493], sL(w) = 0.6629306106236152\n","Iterations 377: w: [0.81259828 2.84304807 2.75550295 3.47292435 5.11502211], sL(w) = 0.6629926971577687\n","Iterations 378: w: [0.81268053 2.84267844 2.75561145 3.47315542 5.11496945], sL(w) = 0.6630545950096162\n","Iterations 379: w: [0.81276252 2.84230994 2.75571961 3.47338577 5.11491695], sL(w) = 0.6631163052471177\n","Iterations 380: w: [0.81284427 2.84194257 2.75582745 3.47361542 5.11486462], sL(w) = 0.6631778289289534\n","Iterations 381: w: [0.81292576 2.84157632 2.75593495 3.47384437 5.11481244], sL(w) = 0.6632391671049485\n","Iterations 382: w: [0.81300701 2.84121119 2.75604213 3.47407262 5.11476042], sL(w) = 0.6633003208173672\n","Iterations 383: w: [0.81308801 2.84084717 2.75614898 3.47430018 5.11470857], sL(w) = 0.6633612910992447\n","Iterations 384: w: [0.81316876 2.84048425 2.75625551 3.47452704 5.11465687], sL(w) = 0.6634220789746096\n","Iterations 385: w: [0.81324927 2.84012243 2.75636172 3.47475322 5.11460532], sL(w) = 0.6634826854595317\n","Iterations 386: w: [0.81332953 2.8397617  2.7564676  3.47497872 5.11455393], sL(w) = 0.6635431115618389\n","Iterations 387: w: [0.81340955 2.83940206 2.75657317 3.47520353 5.1145027 ], sL(w) = 0.6636033582815296\n","Iterations 388: w: [0.81348934 2.83904349 2.75667842 3.47542768 5.11445162], sL(w) = 0.6636634266102619\n","Iterations 389: w: [0.81356888 2.838686   2.75678336 3.47565115 5.1144007 ], sL(w) = 0.6637233175315372\n","Iterations 390: w: [0.81364818 2.83832958 2.75688798 3.47587395 5.11434992], sL(w) = 0.6637830320208457\n","Iterations 391: w: [0.81372725 2.83797422 2.7569923  3.47609609 5.1142993 ], sL(w) = 0.6638425710458163\n","Iterations 392: w: [0.81380608 2.83761991 2.7570963  3.47631757 5.11424883], sL(w) = 0.6639019355667976\n","Iterations 393: w: [0.81388468 2.83726665 2.75719999 3.4765384  5.11419851], sL(w) = 0.6639611265362243\n","Iterations 394: w: [0.81396305 2.83691444 2.75730338 3.47675857 5.11414834], sL(w) = 0.6640201448985759\n","Iterations 395: w: [0.81404118 2.83656326 2.75740647 3.47697809 5.11409832], sL(w) = 0.6640789915916058\n","Iterations 396: w: [0.81411908 2.83621312 2.75750925 3.47719697 5.11404844], sL(w) = 0.6641376675446777\n","Iterations 397: w: [0.81419676 2.835864   2.75761173 3.4774152  5.11399871], sL(w) = 0.6641961736803084\n","Iterations 398: w: [0.8142742  2.83551591 2.75771391 3.4776328  5.11394913], sL(w) = 0.664254510914135\n","Iterations 399: w: [0.81435142 2.83516883 2.75781579 3.47784976 5.11389969], sL(w) = 0.6643126801542563\n","Iterations 400: w: [0.81442842 2.83482276 2.75791738 3.47806609 5.11385039], sL(w) = 0.6643706823007771\n","Iterations 401: w: [0.81450519 2.8344777  2.75801867 3.47828179 5.11380124], sL(w) = 0.6644285182478284\n","Iterations 402: w: [0.81458174 2.83413364 2.75811967 3.47849686 5.11375223], sL(w) = 0.6644861888824921\n","Iterations 403: w: [0.81465807 2.83379057 2.75822038 3.47871132 5.11370337], sL(w) = 0.6645436950849338\n","Iterations 404: w: [0.81473417 2.83344849 2.7583208  3.47892515 5.11365464], sL(w) = 0.6646010377274058\n","Iterations 405: w: [0.81481006 2.83310739 2.75842093 3.47913838 5.11360606], sL(w) = 0.6646582176767043\n","Iterations 406: w: [0.81488573 2.83276727 2.75852077 3.47935098 5.11355761], sL(w) = 0.6647152357919067\n","Iterations 407: w: [0.81496118 2.83242812 2.75862033 3.47956298 5.11350931], sL(w) = 0.6647720929264066\n","Iterations 408: w: [0.81503642 2.83208994 2.7587196  3.47977438 5.11346114], sL(w) = 0.664828789926406\n","Iterations 409: w: [0.81511144 2.83175273 2.75881859 3.47998517 5.11341311], sL(w) = 0.6648853276320056\n","Iterations 410: w: [0.81518625 2.83141647 2.7589173  3.48019537 5.11336521], sL(w) = 0.6649417068765034\n","Iterations 411: w: [0.81526084 2.83108116 2.75901573 3.48040497 5.11331746], sL(w) = 0.6649979284871188\n","Iterations 412: w: [0.81533523 2.83074681 2.75911389 3.48061397 5.11326983], sL(w) = 0.6650539932842013\n","Iterations 413: w: [0.8154094  2.83041339 2.75921176 3.48082239 5.11322235], sL(w) = 0.6651099020823442\n","Iterations 414: w: [0.81548337 2.83008091 2.75930936 3.48103022 5.11317499], sL(w) = 0.6651656556904515\n","Iterations 415: w: [0.81555712 2.82974937 2.75940669 3.48123747 5.11312777], sL(w) = 0.6652212549103638\n","Iterations 416: w: [0.81563067 2.82941875 2.75950375 3.48144413 5.11308068], sL(w) = 0.6652767005383884\n","Iterations 417: w: [0.81570402 2.82908906 2.75960053 3.48165022 5.11303373], sL(w) = 0.6653319933643298\n","Iterations 418: w: [0.81577716 2.82876029 2.75969705 3.48185574 5.1129869 ], sL(w) = 0.6653871341729478\n","Iterations 419: w: [0.81585009 2.82843242 2.7597933  3.48206068 5.11294021], sL(w) = 0.6654421237419235\n","Iterations 420: w: [0.81592283 2.82810547 2.75988928 3.48226506 5.11289364], sL(w) = 0.6654969628439626\n","Iterations 421: w: [0.81599536 2.82777942 2.75998499 3.48246887 5.1128472 ], sL(w) = 0.6655516522458202\n","Iterations 422: w: [0.81606769 2.82745428 2.76008044 3.48267212 5.1128009 ], sL(w) = 0.6656061927088123\n","Iterations 423: w: [0.81613982 2.82713002 2.76017563 3.4828748  5.11275472], sL(w) = 0.66566058498816\n","Iterations 424: w: [0.81621175 2.82680666 2.76027056 3.48307694 5.11270866], sL(w) = 0.6657148298334394\n","Iterations 425: w: [0.81628349 2.82648418 2.76036523 3.48327851 5.11266274], sL(w) = 0.6657689279894838\n","Iterations 426: w: [0.81635503 2.82616259 2.76045964 3.48347954 5.11261694], sL(w) = 0.665822880194193\n","Iterations 427: w: [0.81642637 2.82584187 2.76055379 3.48368002 5.11257126], sL(w) = 0.6658766871812333\n","Iterations 428: w: [0.81649752 2.82552203 2.76064769 3.48387995 5.11252571], sL(w) = 0.665930349678877\n","Iterations 429: w: [0.81656848 2.82520305 2.76074133 3.48407934 5.11248028], sL(w) = 0.665983868409059\n","Iterations 430: w: [0.81663924 2.82488493 2.76083472 3.48427819 5.11243498], sL(w) = 0.6660372440894918\n","Iterations 431: w: [0.81670981 2.82456768 2.76092786 3.4844765  5.1123898 ], sL(w) = 0.666090477432418\n","Iterations 432: w: [0.81678019 2.82425128 2.76102074 3.48467427 5.11234474], sL(w) = 0.6661435691445056\n","Iterations 433: w: [0.81685038 2.82393573 2.76111338 3.48487152 5.1122998 ], sL(w) = 0.6661965199272142\n","Iterations 434: w: [0.81692039 2.82362103 2.76120577 3.48506823 5.11225499], sL(w) = 0.6662493304777797\n","Iterations 435: w: [0.8169902  2.82330717 2.76129791 3.48526442 5.11221029], sL(w) = 0.6663020014879633\n","Iterations 436: w: [0.81705983 2.82299415 2.76138981 3.48546009 5.11216571], sL(w) = 0.666354533643746\n","Iterations 437: w: [0.81712927 2.82268197 2.76148146 3.48565523 5.11212126], sL(w) = 0.6664069276271545\n","Iterations 438: w: [0.81719853 2.82237061 2.76157286 3.48584985 5.11207692], sL(w) = 0.6664591841152757\n","Iterations 439: w: [0.8172676  2.82206008 2.76166403 3.48604396 5.1120327 ], sL(w) = 0.6665113037800616\n","Iterations 440: w: [0.81733649 2.82175037 2.76175495 3.48623755 5.11198859], sL(w) = 0.6665632872887425\n","Iterations 441: w: [0.81740519 2.82144148 2.76184564 3.48643064 5.11194461], sL(w) = 0.6666151353031724\n","Iterations 442: w: [0.81747372 2.8211334  2.76193608 3.48662321 5.11190074], sL(w) = 0.6666668484814583\n","Iterations 443: w: [0.81754207 2.82082614 2.76202629 3.48681528 5.11185698], sL(w) = 0.6667184274768175\n","Iterations 444: w: [0.81761023 2.82051967 2.76211626 3.48700684 5.11181334], sL(w) = 0.6667698729374582\n","Iterations 445: w: [0.81767822 2.82021401 2.762206   3.4871979  5.11176981], sL(w) = 0.6668211855078647\n","Iterations 446: w: [0.81774603 2.81990915 2.7622955  3.48738846 5.1117264 ], sL(w) = 0.6668723658267678\n","Iterations 447: w: [0.81781366 2.81960509 2.76238477 3.48757853 5.1116831 ], sL(w) = 0.6669234145291991\n","Iterations 448: w: [0.81788111 2.81930181 2.76247381 3.4877681  5.11163992], sL(w) = 0.6669743322455806\n","Iterations 449: w: [0.81794839 2.81899932 2.76256261 3.48795718 5.11159685], sL(w) = 0.6670251196015848\n","Iterations 450: w: [0.8180155  2.81869761 2.76265119 3.48814577 5.11155388], sL(w) = 0.6670757772188608\n","Iterations 451: w: [0.81808243 2.81839668 2.76273954 3.48833387 5.11151103], sL(w) = 0.6671263057148622\n","Iterations 452: w: [0.81814919 2.81809653 2.76282766 3.48852149 5.11146829], sL(w) = 0.6671767057025864\n","Iterations 453: w: [0.81821578 2.81779715 2.76291555 3.48870863 5.11142566], sL(w) = 0.66722697779028\n","Iterations 454: w: [0.8182822  2.81749854 2.76300322 3.48889528 5.11138314], sL(w) = 0.6672771225829289\n","Iterations 455: w: [0.81834844 2.81720069 2.76309067 3.48908146 5.11134073], sL(w) = 0.6673271406806119\n","Iterations 456: w: [0.81841452 2.8169036  2.76317789 3.48926716 5.11129843], sL(w) = 0.6673770326795824\n","Iterations 457: w: [0.81848043 2.81660727 2.76326489 3.48945239 5.11125624], sL(w) = 0.6674267991719394\n","Iterations 458: w: [0.81854616 2.81631169 2.76335167 3.48963715 5.11121415], sL(w) = 0.6674764407457543\n","Iterations 459: w: [0.81861174 2.81601686 2.76343823 3.48982144 5.11117217], sL(w) = 0.6675259579852707\n","Iterations 460: w: [0.81867714 2.81572278 2.76352457 3.49000526 5.1111303 ], sL(w) = 0.6675753514702923\n","Iterations 461: w: [0.81874238 2.81542944 2.7636107  3.49018862 5.11108853], sL(w) = 0.6676246217766126\n","Iterations 462: w: [0.81880746 2.81513684 2.7636966  3.49037151 5.11104687], sL(w) = 0.6676737694770225\n","Iterations 463: w: [0.81887237 2.81484498 2.76378229 3.49055395 5.11100531], sL(w) = 0.6677227951389585\n","Iterations 464: w: [0.81893712 2.81455385 2.76386777 3.49073592 5.11096386], sL(w) = 0.667771699327263\n","Iterations 465: w: [0.81900171 2.81426345 2.76395303 3.49091745 5.11092251], sL(w) = 0.6678204826023969\n","Iterations 466: w: [0.81906613 2.81397377 2.76403808 3.49109851 5.11088127], sL(w) = 0.6678691455212504\n","Iterations 467: w: [0.81913039 2.81368482 2.76412291 3.49127913 5.11084013], sL(w) = 0.6679176886368234\n","Iterations 468: w: [0.8191945  2.81339659 2.76420754 3.49145929 5.11079909], sL(w) = 0.6679661124984833\n","Iterations 469: w: [0.81925844 2.81310907 2.76429195 3.49163901 5.11075815], sL(w) = 0.6680144176517709\n","Iterations 470: w: [0.81932222 2.81282226 2.76437616 3.49181829 5.11071732], sL(w) = 0.6680626046387247\n","Iterations 471: w: [0.81938585 2.81253616 2.76446016 3.49199712 5.11067658], sL(w) = 0.6681106739982732\n","Iterations 472: w: [0.81944932 2.81225077 2.76454395 3.4921755  5.11063595], sL(w) = 0.6681586262645023\n","Iterations 473: w: [0.81951263 2.81196608 2.76462754 3.49235345 5.11059542], sL(w) = 0.6682064619691164\n","Iterations 474: w: [0.81957579 2.8116821  2.76471092 3.49253096 5.11055498], sL(w) = 0.6682541816396065\n","Iterations 475: w: [0.81963879 2.8113988  2.76479409 3.49270804 5.11051465], sL(w) = 0.6683017858004412\n","Iterations 476: w: [0.81970164 2.8111162  2.76487706 3.49288468 5.11047442], sL(w) = 0.6683492749720995\n","Iterations 477: w: [0.81976433 2.81083429 2.76495984 3.49306089 5.11043428], sL(w) = 0.6683966496720187\n","Iterations 478: w: [0.81982687 2.81055307 2.7650424  3.49323668 5.11039424], sL(w) = 0.668443910414093\n","Iterations 479: w: [0.81988926 2.81027253 2.76512477 3.49341203 5.1103543 ], sL(w) = 0.6684910577091581\n","Iterations 480: w: [0.8199515  2.80999267 2.76520694 3.49358696 5.11031446], sL(w) = 0.6685380920643536\n","Iterations 481: w: [0.82001358 2.80971349 2.76528891 3.49376146 5.11027471], sL(w) = 0.6685850139836246\n","Iterations 482: w: [0.82007552 2.80943499 2.76537068 3.49393555 5.11023506], sL(w) = 0.668631823967458\n","Iterations 483: w: [0.8201373  2.80915715 2.76545226 3.49410921 5.11019551], sL(w) = 0.6686785225127576\n","Iterations 484: w: [0.82019894 2.80887999 2.76553364 3.49428246 5.11015605], sL(w) = 0.6687251101145747\n","Iterations 485: w: [0.82026042 2.80860349 2.76561482 3.49445528 5.11011669], sL(w) = 0.6687715872630988\n","Iterations 486: w: [0.82032176 2.80832765 2.76569581 3.4946277  5.11007742], sL(w) = 0.66881795444696\n","Iterations 487: w: [0.82038296 2.80805247 2.76577661 3.4947997  5.11003824], sL(w) = 0.6688642121497763\n","Iterations 488: w: [0.820444   2.80777795 2.76585721 3.49497129 5.10999916], sL(w) = 0.6689103608534954\n","Iterations 489: w: [0.82050491 2.80750408 2.76593762 3.49514248 5.10996017], sL(w) = 0.6689564010369292\n","Iterations 490: w: [0.82056566 2.80723087 2.76601784 3.49531325 5.10992127], sL(w) = 0.6690023331751953\n","Iterations 491: w: [0.82062627 2.8069583  2.76609787 3.49548362 5.10988247], sL(w) = 0.6690481577400091\n","Iterations 492: w: [0.82068674 2.80668637 2.76617771 3.49565359 5.10984376], sL(w) = 0.6690938752010506\n","Iterations 493: w: [0.82074707 2.80641509 2.76625737 3.49582316 5.10980514], sL(w) = 0.6691394860243935\n","Iterations 494: w: [0.82080725 2.80614445 2.76633683 3.49599232 5.10976661], sL(w) = 0.6691849906739916\n","Iterations 495: w: [0.82086729 2.80587445 2.76641611 3.49616109 5.10972818], sL(w) = 0.6692303896093919\n","Iterations 496: w: [0.82092719 2.80560508 2.7664952  3.49632946 5.10968983], sL(w) = 0.6692756832883849\n","Iterations 497: w: [0.82098695 2.80533634 2.76657411 3.49649744 5.10965157], sL(w) = 0.6693208721652147\n","Iterations 498: w: [0.82104656 2.80506823 2.76665283 3.49666502 5.10961341], sL(w) = 0.6693659566922109\n","Iterations 499: w: [0.82110604 2.80480074 2.76673137 3.49683221 5.10957533], sL(w) = 0.6694109373174156\n","Iterations 500: w: [0.82116538 2.80453388 2.76680973 3.49699902 5.10953734], sL(w) = 0.6694558144872836\n","Iterations 501: w: [0.82122458 2.80426764 2.7668879  3.49716543 5.10949944], sL(w) = 0.6695005886452641\n","Iterations 502: w: [0.82128365 2.80400202 2.7669659  3.49733146 5.10946163], sL(w) = 0.6695452602313942\n","Iterations 503: w: [0.82134258 2.80373701 2.76704371 3.4974971  5.1094239 ], sL(w) = 0.6695898296838915\n","Iterations 504: w: [0.82140137 2.80347261 2.76712134 3.49766236 5.10938627], sL(w) = 0.6696342974374773\n","Iterations 505: w: [0.82146002 2.80320882 2.7671988  3.49782724 5.10934872], sL(w) = 0.6696786639241674\n","Iterations 506: w: [0.82151854 2.80294564 2.76727608 3.49799174 5.10931125], sL(w) = 0.6697229295737985\n","Iterations 507: w: [0.82157692 2.80268307 2.76735317 3.49815587 5.10927388], sL(w) = 0.6697670948131047\n","Iterations 508: w: [0.82163517 2.8024211  2.7674301  3.49831961 5.10923659], sL(w) = 0.6698111600661057\n","Iterations 509: w: [0.82169329 2.80215972 2.76750684 3.49848298 5.10919938], sL(w) = 0.6698551257545884\n","Iterations 510: w: [0.82175128 2.80189895 2.76758342 3.49864598 5.10916226], sL(w) = 0.6698989922979444\n","Iterations 511: w: [0.82180913 2.80163877 2.76765981 3.49880861 5.10912523], sL(w) = 0.6699427601124313\n","Iterations 512: w: [0.82186685 2.80137918 2.76773604 3.49897086 5.10908827], sL(w) = 0.6699864296118825\n","Iterations 513: w: [0.82192443 2.80112018 2.76781209 3.49913275 5.10905141], sL(w) = 0.6700300012078448\n","Iterations 514: w: [0.82198189 2.80086176 2.76788797 3.49929427 5.10901462], sL(w) = 0.6700734753087239\n","Iterations 515: w: [0.82203922 2.80060393 2.76796367 3.49945543 5.10897792], sL(w) = 0.6701168523215112\n","Iterations 516: w: [0.82209642 2.80034668 2.76803921 3.49961622 5.10894131], sL(w) = 0.6701601326493899\n","Iterations 517: w: [0.82215349 2.80009002 2.76811458 3.49977665 5.10890477], sL(w) = 0.6702033166942567\n","Iterations 518: w: [0.82221043 2.79983393 2.76818977 3.49993671 5.10886832], sL(w) = 0.670246404854818\n","Iterations 519: w: [0.82226724 2.79957841 2.7682648  3.50009642 5.10883195], sL(w) = 0.6702893975278339\n","Iterations 520: w: [0.82232392 2.79932347 2.76833966 3.50025577 5.10879566], sL(w) = 0.6703322951074732\n","Iterations 521: w: [0.82238048 2.79906909 2.76841435 3.50041477 5.10875946], sL(w) = 0.6703750979856719\n","Iterations 522: w: [0.82243691 2.79881529 2.76848888 3.50057341 5.10872333], sL(w) = 0.6704178065517938\n","Iterations 523: w: [0.82249321 2.79856205 2.76856324 3.50073169 5.10868729], sL(w) = 0.6704604211926896\n","Iterations 524: w: [0.82254939 2.79830937 2.76863744 3.50088963 5.10865132], sL(w) = 0.6705029422932437\n","Iterations 525: w: [0.82260545 2.79805725 2.76871147 3.50104721 5.10861544], sL(w) = 0.6705453702361378\n","Iterations 526: w: [0.82266138 2.79780569 2.76878534 3.50120445 5.10857963], sL(w) = 0.6705877054013167\n","Iterations 527: w: [0.82271718 2.79755469 2.76885904 3.50136133 5.10854391], sL(w) = 0.6706299481667289\n","Iterations 528: w: [0.82277287 2.79730424 2.76893259 3.50151787 5.10850826], sL(w) = 0.6706720989085233\n","Iterations 529: w: [0.82282843 2.79705434 2.76900597 3.50167407 5.10847269], sL(w) = 0.6707141579994614\n","Iterations 530: w: [0.82288387 2.79680499 2.76907919 3.50182992 5.1084372 ], sL(w) = 0.6707561258106425\n","Iterations 531: w: [0.82293918 2.79655619 2.76915224 3.50198543 5.10840179], sL(w) = 0.6707980027116073\n","Iterations 532: w: [0.82299438 2.79630793 2.76922514 3.5021406  5.10836645], sL(w) = 0.6708397890689367\n","Iterations 533: w: [0.82304945 2.79606022 2.76929788 3.50229543 5.1083312 ], sL(w) = 0.6708814852475109\n","Iterations 534: w: [0.8231044  2.79581304 2.76937046 3.50244993 5.10829602], sL(w) = 0.6709230916094613\n","Iterations 535: w: [0.82315924 2.79556641 2.76944289 3.50260408 5.10826092], sL(w) = 0.6709646085154605\n","Iterations 536: w: [0.82321395 2.79532031 2.76951515 3.50275791 5.10822589], sL(w) = 0.6710060363238106\n","Iterations 537: w: [0.82326854 2.79507474 2.76958726 3.50291139 5.10819094], sL(w) = 0.6710473753906324\n","Iterations 538: w: [0.82332302 2.79482971 2.76965922 3.50306455 5.10815606], sL(w) = 0.6710886260704024\n","Iterations 539: w: [0.82337738 2.7945852  2.76973102 3.50321737 5.10812127], sL(w) = 0.6711297887143496\n","Iterations 540: w: [0.82343162 2.79434122 2.76980266 3.50336987 5.10808654], sL(w) = 0.6711708636729536\n","Iterations 541: w: [0.82348574 2.79409777 2.76987415 3.50352203 5.10805189], sL(w) = 0.6712118512941734\n","Iterations 542: w: [0.82353975 2.79385484 2.76994549 3.50367387 5.10801732], sL(w) = 0.6712527519241551\n","Iterations 543: w: [0.82359364 2.79361243 2.77001667 3.50382539 5.10798282], sL(w) = 0.6712935659063829\n","Iterations 544: w: [0.82364742 2.79337055 2.7700877  3.50397657 5.10794839], sL(w) = 0.6713342935827185\n","Iterations 545: w: [0.82370108 2.79312917 2.77015858 3.50412744 5.10791404], sL(w) = 0.6713749352933698\n","Iterations 546: w: [0.82375462 2.79288832 2.77022931 3.50427798 5.10787976], sL(w) = 0.6714154913764514\n","Iterations 547: w: [0.82380806 2.79264797 2.77029989 3.50442821 5.10784556], sL(w) = 0.6714559621679431\n","Iterations 548: w: [0.82386137 2.79240814 2.77037031 3.50457811 5.10781143], sL(w) = 0.6714963480020368\n","Iterations 549: w: [0.82391458 2.79216881 2.77044059 3.50472769 5.10777737], sL(w) = 0.6715366492109098\n","Iterations 550: w: [0.82396767 2.79193    2.77051072 3.50487696 5.10774338], sL(w) = 0.671576866125109\n","Iterations 551: w: [0.82402065 2.79169168 2.77058071 3.50502592 5.10770946], sL(w) = 0.6716169990724348\n","Iterations 552: w: [0.82407352 2.79145387 2.77065054 3.50517455 5.10767562], sL(w) = 0.6716570483801672\n","Iterations 553: w: [0.82412627 2.79121656 2.77072023 3.50532288 5.10764185], sL(w) = 0.6716970143723812\n","Iterations 554: w: [0.82417892 2.79097975 2.77078977 3.50547089 5.10760815], sL(w) = 0.6717368973728025\n","Iterations 555: w: [0.82423145 2.79074344 2.77085916 3.50561859 5.10757452], sL(w) = 0.6717766977017092\n","Iterations 556: w: [0.82428387 2.79050762 2.77092841 3.50576599 5.10754096], sL(w) = 0.6718164156786127\n","Iterations 557: w: [0.82433618 2.7902723  2.77099752 3.50591307 5.10750747], sL(w) = 0.6718560516210866\n","Iterations 558: w: [0.82438839 2.79003747 2.77106648 3.50605985 5.10747405], sL(w) = 0.6718956058443607\n","Iterations 559: w: [0.82444048 2.78980312 2.7711353  3.50620632 5.1074407 ], sL(w) = 0.6719350786626416\n","Iterations 560: w: [0.82449247 2.78956926 2.77120397 3.50635249 5.10740742], sL(w) = 0.6719744703875506\n","Iterations 561: w: [0.82454435 2.78933589 2.77127251 3.50649835 5.10737421], sL(w) = 0.6720137813300889\n","Iterations 562: w: [0.82459612 2.78910301 2.7713409  3.50664391 5.10734107], sL(w) = 0.6720530117987206\n","Iterations 563: w: [0.82464778 2.7888706  2.77140914 3.50678917 5.107308  ], sL(w) = 0.6720921620999692\n","Iterations 564: w: [0.82469934 2.78863867 2.77147725 3.50693413 5.10727499], sL(w) = 0.6721312325394241\n","Iterations 565: w: [0.82475079 2.78840723 2.77154522 3.50707879 5.10724206], sL(w) = 0.6721702234201199\n","Iterations 566: w: [0.82480213 2.78817626 2.77161305 3.50722315 5.10720919], sL(w) = 0.6722091350438253\n","Iterations 567: w: [0.82485337 2.78794576 2.77168074 3.50736722 5.10717639], sL(w) = 0.6722479677112493\n","Iterations 568: w: [0.8249045  2.78771573 2.77174829 3.50751099 5.10714365], sL(w) = 0.6722867217204666\n","Iterations 569: w: [0.82495553 2.78748618 2.7718157  3.50765446 5.10711099], sL(w) = 0.6723253973685394\n","Iterations 570: w: [0.82500645 2.7872571  2.77188298 3.50779765 5.10707839], sL(w) = 0.672363994950502\n","Iterations 571: w: [0.82505727 2.78702848 2.77195011 3.50794054 5.10704586], sL(w) = 0.6724025147593966\n","Iterations 572: w: [0.82510798 2.78680033 2.77201711 3.50808314 5.10701339], sL(w) = 0.6724409570876918\n","Iterations 573: w: [0.8251586  2.78657264 2.77208398 3.50822545 5.10698099], sL(w) = 0.672479322225534\n","Iterations 574: w: [0.82520911 2.78634542 2.77215071 3.50836747 5.10694866], sL(w) = 0.6725176104622403\n","Iterations 575: w: [0.82525951 2.78611865 2.7722173  3.5085092  5.10691639], sL(w) = 0.672555822084633\n","Iterations 576: w: [0.82530982 2.78589235 2.77228376 3.50865065 5.10688419], sL(w) = 0.6725939573779703\n","Iterations 577: w: [0.82536002 2.7856665  2.77235009 3.50879181 5.10685205], sL(w) = 0.6726320166263763\n","Iterations 578: w: [0.82541012 2.7854411  2.77241628 3.50893268 5.10681998], sL(w) = 0.6726700001125328\n","Iterations 579: w: [0.82546012 2.78521616 2.77248234 3.50907327 5.10678797], sL(w) = 0.6727079081169568\n","Iterations 580: w: [0.82551002 2.78499167 2.77254826 3.50921358 5.10675602], sL(w) = 0.6727457409196359\n","Iterations 581: w: [0.82555982 2.78476763 2.77261406 3.50935361 5.10672415], sL(w) = 0.6727834987985217\n","Iterations 582: w: [0.82560952 2.78454404 2.77267972 3.50949336 5.10669233], sL(w) = 0.672821182029523\n","Iterations 583: w: [0.82565912 2.7843209  2.77274525 3.50963283 5.10666058], sL(w) = 0.6728587908875888\n","Iterations 584: w: [0.82570862 2.7840982  2.77281065 3.50977202 5.10662889], sL(w) = 0.6728963256465426\n","Iterations 585: w: [0.82575802 2.78387595 2.77287593 3.50991093 5.10659727], sL(w) = 0.6729337865783247\n","Iterations 586: w: [0.82580732 2.78365413 2.77294107 3.51004957 5.1065657 ], sL(w) = 0.6729711739535585\n","Iterations 587: w: [0.82585653 2.78343276 2.77300608 3.51018793 5.1065342 ], sL(w) = 0.6730084880410611\n","Iterations 588: w: [0.82590564 2.78321182 2.77307096 3.51032602 5.10650277], sL(w) = 0.6730457291084128\n","Iterations 589: w: [0.82595465 2.78299133 2.77313572 3.51046383 5.10647139], sL(w) = 0.673082897422139\n","Iterations 590: w: [0.82600356 2.78277126 2.77320035 3.51060137 5.10644008], sL(w) = 0.673119993246524\n","Iterations 591: w: [0.82605238 2.78255164 2.77326485 3.51073864 5.10640883], sL(w) = 0.67315701684548\n","Iterations 592: w: [0.8261011  2.78233244 2.77332922 3.51087564 5.10637764], sL(w) = 0.6731939684804535\n","Iterations 593: w: [0.82614972 2.78211367 2.77339347 3.51101238 5.10634652], sL(w) = 0.6732308484123397\n","Iterations 594: w: [0.82619825 2.78189534 2.77345759 3.51114884 5.10631545], sL(w) = 0.6732676569005835\n","Iterations 595: w: [0.82624668 2.78167743 2.77352159 3.51128504 5.10628444], sL(w) = 0.6733043942024535\n","Iterations 596: w: [0.82629502 2.78145994 2.77358546 3.51142097 5.1062535 ], sL(w) = 0.6733410605746685\n","Iterations 597: w: [0.82634327 2.78124289 2.7736492  3.51155663 5.10622262], sL(w) = 0.6733776562725134\n","Iterations 598: w: [0.82639142 2.78102625 2.77371283 3.51169203 5.10619179], sL(w) = 0.6734141815496562\n","Iterations 599: w: [0.82643947 2.78081003 2.77377633 3.51182717 5.10616103], sL(w) = 0.6734506366582818\n","Iterations 600: w: [0.82648744 2.78059424 2.7738397  3.51196204 5.10613033], sL(w) = 0.6734870218498392\n","Iterations 601: w: [0.82653531 2.78037886 2.77390295 3.51209665 5.10609968], sL(w) = 0.6735233373738775\n","Iterations 602: w: [0.82658308 2.7801639  2.77396608 3.51223101 5.1060691 ], sL(w) = 0.6735595834793575\n","Iterations 603: w: [0.82663077 2.77994936 2.77402909 3.5123651  5.10603857], sL(w) = 0.6735957604130348\n","Iterations 604: w: [0.82667836 2.77973523 2.77409198 3.51249893 5.10600811], sL(w) = 0.6736318684212365\n","Iterations 605: w: [0.82672586 2.77952151 2.77415475 3.51263251 5.1059777 ], sL(w) = 0.6736679077485211\n","Iterations 606: w: [0.82677327 2.7793082  2.77421739 3.51276583 5.10594735], sL(w) = 0.6737038786376859\n","Iterations 607: w: [0.82682059 2.7790953  2.77427992 3.51289889 5.10591706], sL(w) = 0.6737397813316479\n","Iterations 608: w: [0.82686781 2.77888281 2.77434233 3.5130317  5.10588683], sL(w) = 0.6737756160707769\n","Iterations 609: w: [0.82691495 2.77867073 2.77440461 3.51316425 5.10585665], sL(w) = 0.6738113830945686\n","Iterations 610: w: [0.826962   2.77845905 2.77446678 3.51329655 5.10582654], sL(w) = 0.6738470826419859\n","Iterations 611: w: [0.82700895 2.77824777 2.77452883 3.5134286  5.10579648], sL(w) = 0.6738827149497937\n","Iterations 612: w: [0.82705582 2.7780369  2.77459076 3.5135604  5.10576648], sL(w) = 0.6739182802540492\n","Iterations 613: w: [0.8271026  2.77782643 2.77465258 3.51369194 5.10573653], sL(w) = 0.6739537787893856\n","Iterations 614: w: [0.82714929 2.77761635 2.77471427 3.51382324 5.10570664], sL(w) = 0.6739892107893022\n","Iterations 615: w: [0.82719589 2.77740668 2.77477585 3.51395429 5.10567681], sL(w) = 0.6740245764861389\n","Iterations 616: w: [0.8272424  2.7771974  2.77483732 3.51408509 5.10564704], sL(w) = 0.6740598761111901\n","Iterations 617: w: [0.82728882 2.77698852 2.77489867 3.51421564 5.10561732], sL(w) = 0.6740951098943295\n","Iterations 618: w: [0.82733516 2.77678003 2.7749599  3.51434595 5.10558766], sL(w) = 0.6741302780643701\n","Iterations 619: w: [0.8273814  2.77657193 2.77502102 3.51447601 5.10555805], sL(w) = 0.6741653808488169\n","Iterations 620: w: [0.82742757 2.77636422 2.77508202 3.51460583 5.1055285 ], sL(w) = 0.6742004184745838\n","Iterations 621: w: [0.82747364 2.77615691 2.77514291 3.5147354  5.10549901], sL(w) = 0.674235391166423\n","Iterations 622: w: [0.82751963 2.77594998 2.77520368 3.51486473 5.10546957], sL(w) = 0.6742702991491143\n","Iterations 623: w: [0.82756553 2.77574344 2.77526434 3.51499382 5.10544019], sL(w) = 0.6743051426451577\n","Iterations 624: w: [0.82761135 2.77553728 2.77532489 3.51512267 5.10541086], sL(w) = 0.6743399218765335\n","Iterations 625: w: [0.82765708 2.77533151 2.77538533 3.51525128 5.10538158], sL(w) = 0.6743746370643136\n","Iterations 626: w: [0.82770272 2.77512612 2.77544565 3.51537964 5.10535237], sL(w) = 0.6744092884280477\n","Iterations 627: w: [0.82774828 2.77492111 2.77550586 3.51550777 5.1053232 ], sL(w) = 0.6744438761861759\n","Iterations 628: w: [0.82779376 2.77471648 2.77556596 3.51563567 5.10529409], sL(w) = 0.6744784005566654\n","Iterations 629: w: [0.82783915 2.77451224 2.77562595 3.51576332 5.10526503], sL(w) = 0.6745128617558362\n","Iterations 630: w: [0.82788446 2.77430837 2.77568582 3.51589074 5.10523603], sL(w) = 0.6745472599987945\n","Iterations 631: w: [0.82792968 2.77410487 2.77574559 3.51601792 5.10520708], sL(w) = 0.6745815955002225\n","Iterations 632: w: [0.82797482 2.77390175 2.77580525 3.51614487 5.10517819], sL(w) = 0.6746158684729312\n","Iterations 633: w: [0.82801987 2.77369901 2.77586479 3.51627159 5.10514934], sL(w) = 0.6746500791291676\n","Iterations 634: w: [0.82806485 2.77349664 2.77592423 3.51639807 5.10512055], sL(w) = 0.6746842276797373\n","Iterations 635: w: [0.82810974 2.77329464 2.77598356 3.51652432 5.10509182], sL(w) = 0.6747183143352694\n","Iterations 636: w: [0.82815455 2.773093   2.77604278 3.51665034 5.10506313], sL(w) = 0.6747523393047234\n","Iterations 637: w: [0.82819927 2.77289174 2.77610189 3.51677613 5.1050345 ], sL(w) = 0.6747863027955107\n","Iterations 638: w: [0.82824392 2.77269085 2.7761609  3.51690169 5.10500592], sL(w) = 0.6748202050148007\n","Iterations 639: w: [0.82828848 2.77249032 2.77621979 3.51702701 5.1049774 ], sL(w) = 0.6748540461687059\n","Iterations 640: w: [0.82833296 2.77229016 2.77627858 3.51715212 5.10494892], sL(w) = 0.6748878264623119\n","Iterations 641: w: [0.82837736 2.77209036 2.77633726 3.51727699 5.1049205 ], sL(w) = 0.6749215460993534\n","Iterations 642: w: [0.82842168 2.77189092 2.77639584 3.51740164 5.10489213], sL(w) = 0.6749552052826949\n","Iterations 643: w: [0.82846592 2.77169184 2.77645431 3.51752606 5.10486381], sL(w) = 0.674988804213901\n","Iterations 644: w: [0.82851008 2.77149313 2.77651268 3.51765025 5.10483554], sL(w) = 0.6750223430944302\n","Iterations 645: w: [0.82855416 2.77129477 2.77657094 3.51777423 5.10480733], sL(w) = 0.675055822124025\n","Iterations 646: w: [0.82859816 2.77109677 2.77662909 3.51789797 5.10477916], sL(w) = 0.6750892415015844\n","Iterations 647: w: [0.82864208 2.77089913 2.77668714 3.5180215  5.10475105], sL(w) = 0.6751226014253543\n","Iterations 648: w: [0.82868592 2.77070184 2.77674509 3.5181448  5.10472298], sL(w) = 0.6751559020922483\n","Iterations 649: w: [0.82872968 2.77050491 2.77680293 3.51826788 5.10469497], sL(w) = 0.6751891436984987\n","Iterations 650: w: [0.82877337 2.77030833 2.77686067 3.51839075 5.10466701], sL(w) = 0.6752223264393261\n","Iterations 651: w: [0.82881697 2.7701121  2.7769183  3.51851339 5.10463909], sL(w) = 0.6752554505084971\n","Iterations 652: w: [0.8288605  2.76991622 2.77697583 3.51863581 5.10461123], sL(w) = 0.6752885160995151\n","Iterations 653: w: [0.82890395 2.76972069 2.77703326 3.51875801 5.10458342], sL(w) = 0.6753215234053283\n","Iterations 654: w: [0.82894732 2.76952551 2.77709059 3.51888    5.10455565], sL(w) = 0.6753544726164011\n","Iterations 655: w: [0.82899061 2.76933068 2.77714781 3.51900177 5.10452794], sL(w) = 0.6753873639233341\n","Iterations 656: w: [0.82903383 2.76913619 2.77720494 3.51912332 5.10450027], sL(w) = 0.6754201975164202\n","Iterations 657: w: [0.82907697 2.76894205 2.77726196 3.51924465 5.10447266], sL(w) = 0.6754529735836431\n","Iterations 658: w: [0.82912003 2.76874825 2.77731888 3.51936578 5.10444509], sL(w) = 0.6754856923130914\n","Iterations 659: w: [0.82916302 2.7685548  2.7773757  3.51948668 5.10441757], sL(w) = 0.6755183538915368\n","Iterations 660: w: [0.82920593 2.76836168 2.77743243 3.51960738 5.1043901 ], sL(w) = 0.675550958504898\n","Iterations 661: w: [0.82924877 2.76816891 2.77748905 3.51972786 5.10436268], sL(w) = 0.6755835063385236\n","Iterations 662: w: [0.82929153 2.76797648 2.77754557 3.51984813 5.10433531], sL(w) = 0.6756159975767206\n","Iterations 663: w: [0.82933421 2.76778438 2.77760199 3.51996819 5.10430799], sL(w) = 0.6756484324022608\n","Iterations 664: w: [0.82937682 2.76759262 2.77765831 3.52008803 5.10428071], sL(w) = 0.6756808109982827\n","Iterations 665: w: [0.82941936 2.7674012  2.77771454 3.52020767 5.10425348], sL(w) = 0.6757131335459697\n","Iterations 666: w: [0.82946182 2.76721011 2.77777067 3.5203271  5.1042263 ], sL(w) = 0.675745400225973\n","Iterations 667: w: [0.82950421 2.76701935 2.77782669 3.52044632 5.10419917], sL(w) = 0.6757776112186319\n","Iterations 668: w: [0.82954652 2.76682893 2.77788263 3.52056533 5.10417208], sL(w) = 0.6758097667029178\n","Iterations 669: w: [0.82958876 2.76663884 2.77793846 3.52068413 5.10414505], sL(w) = 0.6758418668566508\n","Iterations 670: w: [0.82963092 2.76644908 2.7779942  3.52080273 5.10411806], sL(w) = 0.6758739118576768\n","Iterations 671: w: [0.82967301 2.76625965 2.77804984 3.52092112 5.10409111], sL(w) = 0.6759059018822577\n","Iterations 672: w: [0.82971503 2.76607055 2.77810538 3.52103931 5.10406422], sL(w) = 0.6759378371067997\n","Iterations 673: w: [0.82975698 2.76588178 2.77816083 3.52115729 5.10403736], sL(w) = 0.6759697177047501\n","Iterations 674: w: [0.82979885 2.76569333 2.77821618 3.52127506 5.10401056], sL(w) = 0.6760015438515181\n","Iterations 675: w: [0.82984065 2.7655052  2.77827144 3.52139264 5.1039838 ], sL(w) = 0.6760333157202638\n","Iterations 676: w: [0.82988238 2.76531741 2.7783266  3.52151001 5.10395709], sL(w) = 0.6760650334827468\n","Iterations 677: w: [0.82992403 2.76512993 2.77838167 3.52162718 5.10393043], sL(w) = 0.6760966973110653\n","Iterations 678: w: [0.82996562 2.76494278 2.77843664 3.52174415 5.10390381], sL(w) = 0.6761283073757337\n","Iterations 679: w: [0.83000713 2.76475594 2.77849152 3.52186091 5.10387723], sL(w) = 0.6761598638475848\n","Iterations 680: w: [0.83004857 2.76456943 2.7785463  3.52197748 5.10385071], sL(w) = 0.6761913668953718\n","Iterations 681: w: [0.83008994 2.76438324 2.77860099 3.52209385 5.10382422], sL(w) = 0.6762228166876751\n","Iterations 682: w: [0.83013124 2.76419736 2.77865559 3.52221001 5.10379779], sL(w) = 0.6762542133920547\n","Iterations 683: w: [0.83017247 2.76401181 2.77871009 3.52232599 5.1037714 ], sL(w) = 0.6762855571758224\n","Iterations 684: w: [0.83021363 2.76382656 2.7787645  3.52244176 5.10374505], sL(w) = 0.6763168482047301\n","Iterations 685: w: [0.83025472 2.76364164 2.77881882 3.52255733 5.10371875], sL(w) = 0.6763480866449115\n","Iterations 686: w: [0.83029574 2.76345702 2.77887305 3.52267271 5.10369249], sL(w) = 0.6763792726603658\n","Iterations 687: w: [0.83033669 2.76327272 2.77892718 3.5227879  5.10366628], sL(w) = 0.6764104064150496\n","Iterations 688: w: [0.83037757 2.76308874 2.77898122 3.52290288 5.10364011], sL(w) = 0.6764414880723786\n","Iterations 689: w: [0.83041838 2.76290506 2.77903518 3.52301768 5.10361399], sL(w) = 0.6764725177946902\n","Iterations 690: w: [0.83045912 2.76272169 2.77908904 3.52313228 5.10358791], sL(w) = 0.6765034957435715\n","Iterations 691: w: [0.83049979 2.76253864 2.77914281 3.52324669 5.10356187], sL(w) = 0.6765344220804411\n","Iterations 692: w: [0.83054039 2.76235589 2.77919649 3.5233609  5.10353588], sL(w) = 0.6765652969648348\n","Iterations 693: w: [0.83058093 2.76217344 2.77925008 3.52347492 5.10350993], sL(w) = 0.6765961205566527\n","Iterations 694: w: [0.8306214  2.76199131 2.77930358 3.52358875 5.10348403], sL(w) = 0.6766268930143094\n","Iterations 695: w: [0.83066179 2.76180948 2.77935699 3.52370239 5.10345817], sL(w) = 0.676657614496382\n","Iterations 696: w: [0.83070213 2.76162795 2.77941031 3.52381584 5.10343235], sL(w) = 0.6766882851599014\n","Iterations 697: w: [0.83074239 2.76144673 2.77946354 3.5239291  5.10340658], sL(w) = 0.6767189051618422\n","Iterations 698: w: [0.83078259 2.76126581 2.77951668 3.52404217 5.10338085], sL(w) = 0.6767494746574143\n","Iterations 699: w: [0.83082272 2.76108519 2.77956974 3.52415505 5.10335516], sL(w) = 0.6767799938018952\n","Iterations 700: w: [0.83086278 2.76090488 2.7796227  3.52426775 5.10332952], sL(w) = 0.6768104627504785\n","Iterations 701: w: [0.83090277 2.76072486 2.77967558 3.52438025 5.10330391], sL(w) = 0.6768408816561943\n","Iterations 702: w: [0.8309427  2.76054514 2.77972837 3.52449257 5.10327835], sL(w) = 0.6768712506725427\n","Iterations 703: w: [0.83098257 2.76036572 2.77978107 3.52460471 5.10325284], sL(w) = 0.676901569952189\n","Iterations 704: w: [0.83102236 2.76018659 2.77983369 3.52471666 5.10322736], sL(w) = 0.6769318396464962\n","Iterations 705: w: [0.83106209 2.76000776 2.77988622 3.52482842 5.10320193], sL(w) = 0.6769620599072186\n","Iterations 706: w: [0.83110176 2.75982923 2.77993866 3.52494    5.10317654], sL(w) = 0.6769922308839226\n","Iterations 707: w: [0.83114136 2.75965099 2.77999102 3.52505139 5.10315119], sL(w) = 0.6770223527271161\n","Iterations 708: w: [0.83118089 2.75947304 2.78004329 3.5251626  5.10312589], sL(w) = 0.677052425585223\n","Iterations 709: w: [0.83122036 2.75929539 2.78009547 3.52527363 5.10310062], sL(w) = 0.677082449607252\n","Iterations 710: w: [0.83125976 2.75911803 2.78014757 3.52538448 5.1030754 ], sL(w) = 0.677112424940644\n","Iterations 711: w: [0.8312991  2.75894096 2.78019959 3.52549514 5.10305022], sL(w) = 0.6771423517323175\n","Iterations 712: w: [0.83133838 2.75876418 2.78025151 3.52560563 5.10302507], sL(w) = 0.6771722301290962\n","Iterations 713: w: [0.83137759 2.75858768 2.78030336 3.52571593 5.10299998], sL(w) = 0.6772020602766108\n","Iterations 714: w: [0.83141674 2.75841148 2.78035512 3.52582605 5.10297492], sL(w) = 0.6772318423202797\n","Iterations 715: w: [0.83145582 2.75823556 2.78040679 3.52593599 5.1029499 ], sL(w) = 0.6772615764043055\n","Iterations 716: w: [0.83149484 2.75805993 2.78045838 3.52604576 5.10292492], sL(w) = 0.6772912626726021\n","Iterations 717: w: [0.83153379 2.75788459 2.78050989 3.52615534 5.10289999], sL(w) = 0.6773209012683663\n","Iterations 718: w: [0.83157269 2.75770952 2.78056131 3.52626475 5.10287509], sL(w) = 0.6773504923345511\n","Iterations 719: w: [0.83161151 2.75753475 2.78061266 3.52637398 5.10285024], sL(w) = 0.677380036012832\n","Iterations 720: w: [0.83165028 2.75736025 2.78066391 3.52648304 5.10282542], sL(w) = 0.677409532444433\n","Iterations 721: w: [0.83168898 2.75718604 2.78071509 3.52659191 5.10280065], sL(w) = 0.6774389817707203\n","Iterations 722: w: [0.83172762 2.75701211 2.78076618 3.52670062 5.10277591], sL(w) = 0.6774683841314907\n","Iterations 723: w: [0.8317662  2.75683846 2.78081719 3.52680914 5.10275122], sL(w) = 0.6774977396663983\n","Iterations 724: w: [0.83180472 2.75666508 2.78086812 3.52691749 5.10272656], sL(w) = 0.6775270485142968\n","Iterations 725: w: [0.83184317 2.75649199 2.78091896 3.52702567 5.10270195], sL(w) = 0.6775563108139331\n","Iterations 726: w: [0.83188156 2.75631917 2.78096973 3.52713368 5.10267737], sL(w) = 0.6775855267024729\n","Iterations 727: w: [0.83191989 2.75614664 2.78102041 3.52724151 5.10265284], sL(w) = 0.6776146963173226\n","Iterations 728: w: [0.83195816 2.75597437 2.78107102 3.52734916 5.10262834], sL(w) = 0.6776438197952216\n","Iterations 729: w: [0.83199637 2.75580239 2.78112154 3.52745665 5.10260389], sL(w) = 0.6776728972716155\n","Iterations 730: w: [0.83203452 2.75563067 2.78117198 3.52756397 5.10257947], sL(w) = 0.6777019288824025\n","Iterations 731: w: [0.8320726  2.75545923 2.78122234 3.52767111 5.10255509], sL(w) = 0.6777309147622268\n","Iterations 732: w: [0.83211063 2.75528807 2.78127262 3.52777808 5.10253075], sL(w) = 0.6777598550449476\n","Iterations 733: w: [0.83214859 2.75511717 2.78132282 3.52788488 5.10250645], sL(w) = 0.6777887498647011\n","Iterations 734: w: [0.8321865  2.75494655 2.78137294 3.52799152 5.10248218], sL(w) = 0.6778175993542516\n","Iterations 735: w: [0.83222434 2.7547762  2.78142298 3.52809798 5.10245796], sL(w) = 0.6778464036463623\n","Iterations 736: w: [0.83226212 2.75460612 2.78147295 3.52820428 5.10243377], sL(w) = 0.6778751628726631\n","Iterations 737: w: [0.83229985 2.7544363  2.78152283 3.5283104  5.10240963], sL(w) = 0.6779038771650325\n","Iterations 738: w: [0.83233751 2.75426676 2.78157263 3.52841636 5.10238552], sL(w) = 0.6779325466538234\n","Iterations 739: w: [0.83237512 2.75409748 2.78162236 3.52852216 5.10236145], sL(w) = 0.6779611714692128\n","Iterations 740: w: [0.83241266 2.75392847 2.78167201 3.52862778 5.10233741], sL(w) = 0.6779897517411319\n","Iterations 741: w: [0.83245015 2.75375972 2.78172158 3.52873324 5.10231342], sL(w) = 0.6780182875988573\n","Iterations 742: w: [0.83248757 2.75359124 2.78177107 3.52883854 5.10228946], sL(w) = 0.6780467791704604\n","Iterations 743: w: [0.83252494 2.75342302 2.78182049 3.52894367 5.10226554], sL(w) = 0.6780752265845222\n","Iterations 744: w: [0.83256225 2.75325507 2.78186983 3.52904863 5.10224166], sL(w) = 0.6781036299682363\n","Iterations 745: w: [0.8325995  2.75308738 2.78191909 3.52915343 5.10221782], sL(w) = 0.6781319894487224\n","Iterations 746: w: [0.8326367  2.75291995 2.78196827 3.52925807 5.10219401], sL(w) = 0.6781603051520624\n","Iterations 747: w: [0.83267383 2.75275278 2.78201738 3.52936254 5.10217024], sL(w) = 0.6781885772047479\n","Iterations 748: w: [0.83271091 2.75258588 2.78206641 3.52946685 5.1021465 ], sL(w) = 0.6782168057322753\n","Iterations 749: w: [0.83274793 2.75241923 2.78211536 3.529571   5.10212281], sL(w) = 0.6782449908591724\n","Iterations 750: w: [0.83278489 2.75225284 2.78216424 3.52967498 5.10209915], sL(w) = 0.6782731327094117\n","Iterations 751: w: [0.83282179 2.75208671 2.78221305 3.52977881 5.10207553], sL(w) = 0.6783012314070123\n","Iterations 752: w: [0.83285864 2.75192084 2.78226177 3.52988247 5.10205194], sL(w) = 0.6783292870753017\n","Iterations 753: w: [0.83289543 2.75175522 2.78231043 3.52998598 5.10202839], sL(w) = 0.6783572998371991\n","Iterations 754: w: [0.83293216 2.75158986 2.782359   3.53008932 5.10200488], sL(w) = 0.6783852698145744\n","Iterations 755: w: [0.83296883 2.75142475 2.7824075  3.5301925  5.1019814 ], sL(w) = 0.6784131971292744\n","Iterations 756: w: [0.83300545 2.7512599  2.78245593 3.53029553 5.10195796], sL(w) = 0.6784410819030033\n","Iterations 757: w: [0.83304202 2.75109531 2.78250429 3.53039839 5.10193456], sL(w) = 0.6784689242563122\n","Iterations 758: w: [0.83307852 2.75093096 2.78255256 3.5305011  5.10191119], sL(w) = 0.6784967243095147\n","Iterations 759: w: [0.83311497 2.75076687 2.78260077 3.53060365 5.10188786], sL(w) = 0.6785244821820547\n","Iterations 760: w: [0.83315137 2.75060303 2.7826489  3.53070605 5.10186456], sL(w) = 0.678552197993424\n","Iterations 761: w: [0.8331877  2.75043944 2.78269696 3.53080828 5.1018413 ], sL(w) = 0.6785798718621595\n","Iterations 762: w: [0.83322399 2.7502761  2.78274494 3.53091036 5.10181808], sL(w) = 0.6786075039062852\n","Iterations 763: w: [0.83326021 2.75011301 2.78279285 3.53101229 5.10179489], sL(w) = 0.678635094243978\n","Iterations 764: w: [0.83329639 2.74995017 2.78284069 3.53111405 5.10177174], sL(w) = 0.6786626429928345\n","Iterations 765: w: [0.8333325  2.74978758 2.78288845 3.53121567 5.10174862], sL(w) = 0.6786901502693466\n","Iterations 766: w: [0.83336856 2.74962523 2.78293615 3.53131713 5.10172554], sL(w) = 0.6787176161895901\n","Iterations 767: w: [0.83340457 2.74946313 2.78298377 3.53141843 5.10170249], sL(w) = 0.6787450408696244\n","Iterations 768: w: [0.83344052 2.74930128 2.78303131 3.53151958 5.10167948], sL(w) = 0.6787724244247048\n","Iterations 769: w: [0.83347642 2.74913967 2.78307879 3.53162058 5.1016565 ], sL(w) = 0.6787997669700438\n","Iterations 770: w: [0.83351226 2.74897831 2.78312619 3.53172142 5.10163356], sL(w) = 0.678827068620073\n","Iterations 771: w: [0.83354805 2.74881719 2.78317353 3.53182212 5.10161065], sL(w) = 0.6788543294884569\n","Iterations 772: w: [0.83358378 2.74865631 2.78322079 3.53192266 5.10158777], sL(w) = 0.6788815496881968\n","Iterations 773: w: [0.83361946 2.74849568 2.78326798 3.53202305 5.10156493], sL(w) = 0.678908729333181\n","Iterations 774: w: [0.83365509 2.74833528 2.7833151  3.53212328 5.10154213], sL(w) = 0.6789358685356145\n","Iterations 775: w: [0.83369066 2.74817513 2.78336214 3.53222337 5.10151936], sL(w) = 0.6789629674082857\n","Iterations 776: w: [0.83372618 2.74801522 2.78340912 3.53232331 5.10149662], sL(w) = 0.6789900260619338\n","Iterations 777: w: [0.83376165 2.74785555 2.78345603 3.53242309 5.10147392], sL(w) = 0.6790170446081495\n","Iterations 778: w: [0.83379706 2.74769612 2.78350287 3.53252273 5.10145126], sL(w) = 0.6790440231579871\n","Iterations 779: w: [0.83383242 2.74753693 2.78354963 3.53262222 5.10142862], sL(w) = 0.6790709618212019\n","Iterations 780: w: [0.83386773 2.74737797 2.78359633 3.53272156 5.10140602], sL(w) = 0.679097860707805\n","Iterations 781: w: [0.83390298 2.74721925 2.78364296 3.53282075 5.10138346], sL(w) = 0.6791247199272796\n","Iterations 782: w: [0.83393818 2.74706077 2.78368952 3.53291979 5.10136092], sL(w) = 0.6791515395892928\n","Iterations 783: w: [0.83397333 2.74690253 2.783736   3.53301869 5.10133843], sL(w) = 0.6791783198013835\n","Iterations 784: w: [0.83400843 2.74674451 2.78378242 3.53311743 5.10131596], sL(w) = 0.6792050606719304\n","Iterations 785: w: [0.83404347 2.74658674 2.78382878 3.53321604 5.10129353], sL(w) = 0.6792317623088805\n","Iterations 786: w: [0.83407846 2.7464292  2.78387506 3.53331449 5.10127113], sL(w) = 0.6792584248196792\n","Iterations 787: w: [0.8341134  2.74627189 2.78392127 3.5334128  5.10124877], sL(w) = 0.6792850483109217\n","Iterations 788: w: [0.83414829 2.74611481 2.78396742 3.53351097 5.10122643], sL(w) = 0.6793116328887203\n","Iterations 789: w: [0.83418313 2.74595797 2.7840135  3.53360899 5.10120413], sL(w) = 0.6793381786591423\n","Iterations 790: w: [0.83421791 2.74580135 2.78405951 3.53370686 5.10118187], sL(w) = 0.679364685728082\n","Iterations 791: w: [0.83425265 2.74564497 2.78410545 3.53380459 5.10115964], sL(w) = 0.6793911542006171\n","Iterations 792: w: [0.83428733 2.74548882 2.78415132 3.53390218 5.10113744], sL(w) = 0.6794175841810656\n","Iterations 793: w: [0.83432196 2.7453329  2.78419713 3.53399962 5.10111527], sL(w) = 0.6794439757739442\n","Iterations 794: w: [0.83435654 2.7451772  2.78424287 3.53409692 5.10109313], sL(w) = 0.6794703290834404\n","Iterations 795: w: [0.83439107 2.74502174 2.78428854 3.53419408 5.10107103], sL(w) = 0.6794966442127178\n","Iterations 796: w: [0.83442555 2.7448665  2.78433415 3.5342911  5.10104896], sL(w) = 0.6795229212644627\n","Iterations 797: w: [0.83445998 2.74471149 2.78437969 3.53438797 5.10102692], sL(w) = 0.6795491603419725\n","Iterations 798: w: [0.83449436 2.7445567  2.78442516 3.5344847  5.10100492], sL(w) = 0.6795753615472626\n","Iterations 799: w: [0.83452869 2.74440214 2.78447057 3.53458129 5.10098295], sL(w) = 0.6796015249818622\n","Iterations 800: w: [0.83456297 2.74424781 2.78451591 3.53467774 5.100961  ], sL(w) = 0.6796276507478998\n","Iterations 801: w: [0.83459719 2.7440937  2.78456119 3.53477405 5.10093909], sL(w) = 0.6796537389457205\n","Iterations 802: w: [0.83463137 2.74393981 2.7846064  3.53487022 5.10091722], sL(w) = 0.6796797896767471\n","Iterations 803: w: [0.8346655  2.74378615 2.78465154 3.53496625 5.10089537], sL(w) = 0.6797058030405931\n","Iterations 804: w: [0.83469958 2.74363271 2.78469662 3.53506215 5.10087356], sL(w) = 0.6797317791376267\n","Iterations 805: w: [0.83473361 2.74347949 2.78474163 3.5351579  5.10085178], sL(w) = 0.6797577180668066\n","Iterations 806: w: [0.83476759 2.7433265  2.78478658 3.53525351 5.10083003], sL(w) = 0.6797836199273851\n","Iterations 807: w: [0.83480152 2.74317372 2.78483146 3.53534899 5.10080831], sL(w) = 0.6798094848182855\n","Iterations 808: w: [0.8348354  2.74302117 2.78487628 3.53544433 5.10078662], sL(w) = 0.6798353128376026\n","Iterations 809: w: [0.83486924 2.74286883 2.78492104 3.53553953 5.10076496], sL(w) = 0.679861104083474\n","Iterations 810: w: [0.83490302 2.74271671 2.78496573 3.53563459 5.10074334], sL(w) = 0.6798868586530231\n","Iterations 811: w: [0.83493676 2.74256482 2.78501035 3.53572952 5.10072174], sL(w) = 0.6799125766439446\n","Iterations 812: w: [0.83497044 2.74241314 2.78505491 3.53582431 5.10070018], sL(w) = 0.6799382581531116\n","Iterations 813: w: [0.83500408 2.74226168 2.78509941 3.53591896 5.10067865], sL(w) = 0.6799639032763402\n","Iterations 814: w: [0.83503767 2.74211043 2.78514385 3.53601348 5.10065715], sL(w) = 0.6799895121104587\n","Iterations 815: w: [0.83507121 2.7419594  2.78518822 3.53610787 5.10063568], sL(w) = 0.6800150847503253\n","Iterations 816: w: [0.83510471 2.74180859 2.78523253 3.53620212 5.10061424], sL(w) = 0.6800406212917537\n","Iterations 817: w: [0.83513816 2.74165799 2.78527677 3.53629623 5.10059283], sL(w) = 0.6800661218294759\n","Iterations 818: w: [0.83517155 2.74150761 2.78532095 3.53639021 5.10057145], sL(w) = 0.6800915864579079\n","Iterations 819: w: [0.83520491 2.74135744 2.78536507 3.53648406 5.10055011], sL(w) = 0.6801170152714567\n","Iterations 820: w: [0.83523821 2.74120748 2.78540913 3.53657777 5.10052879], sL(w) = 0.6801424083643358\n","Iterations 821: w: [0.83527147 2.74105774 2.78545312 3.53667135 5.1005075 ], sL(w) = 0.6801677658294164\n","Iterations 822: w: [0.83530467 2.7409082  2.78549705 3.5367648  5.10048624], sL(w) = 0.6801930877606377\n","Iterations 823: w: [0.83533784 2.74075888 2.78554092 3.53685812 5.10046502], sL(w) = 0.6802183742497877\n","Iterations 824: w: [0.83537095 2.74060978 2.78558473 3.5369513  5.10044382], sL(w) = 0.680243625390361\n","Iterations 825: w: [0.83540402 2.74046088 2.78562847 3.53704435 5.10042266], sL(w) = 0.6802688412734124\n","Iterations 826: w: [0.83543704 2.74031219 2.78567216 3.53713727 5.10040152], sL(w) = 0.6802940219911475\n","Iterations 827: w: [0.83547002 2.74016371 2.78571578 3.53723006 5.10038041], sL(w) = 0.680319167635177\n","Iterations 828: w: [0.83550294 2.74001544 2.78575934 3.53732272 5.10035934], sL(w) = 0.6803442782965876\n","Iterations 829: w: [0.83553583 2.73986738 2.78580284 3.53741525 5.10033829], sL(w) = 0.6803693540652993\n","Iterations 830: w: [0.83556866 2.73971953 2.78584628 3.53750765 5.10031727], sL(w) = 0.6803943950323919\n","Iterations 831: w: [0.83560145 2.73957188 2.78588966 3.53759992 5.10029628], sL(w) = 0.6804194012876313\n","Iterations 832: w: [0.83563419 2.73942444 2.78593298 3.53769206 5.10027532], sL(w) = 0.6804443729207538\n","Iterations 833: w: [0.83566689 2.73927721 2.78597623 3.53778407 5.1002544 ], sL(w) = 0.6804693100206725\n","Iterations 834: w: [0.83569954 2.73913018 2.78601943 3.53787595 5.1002335 ], sL(w) = 0.680494212676578\n","Iterations 835: w: [0.83573215 2.73898336 2.78606257 3.53796771 5.10021262], sL(w) = 0.6805190809770535\n","Iterations 836: w: [0.83576471 2.73883674 2.78610564 3.53805933 5.10019178], sL(w) = 0.6805439150108995\n","Iterations 837: w: [0.83579723 2.73869033 2.78614866 3.53815083 5.10017097], sL(w) = 0.6805687148657946\n","Iterations 838: w: [0.83582969 2.73854412 2.78619161 3.5382422  5.10015019], sL(w) = 0.680593480628786\n","Iterations 839: w: [0.83586212 2.73839812 2.78623451 3.53833345 5.10012943], sL(w) = 0.6806182123876818\n","Iterations 840: w: [0.8358945  2.73825231 2.78627735 3.53842456 5.10010871], sL(w) = 0.6806429102295638\n","Iterations 841: w: [0.83592683 2.73810671 2.78632013 3.53851556 5.10008801], sL(w) = 0.6806675742415269\n","Iterations 842: w: [0.83595912 2.73796131 2.78636285 3.53860642 5.10006734], sL(w) = 0.6806922045087963\n","Iterations 843: w: [0.83599137 2.73781611 2.78640551 3.53869716 5.1000467 ], sL(w) = 0.6807168011185029\n","Iterations 844: w: [0.83602357 2.73767111 2.78644811 3.53878778 5.10002609], sL(w) = 0.6807413641561474\n","Iterations 845: w: [0.83605572 2.73752631 2.78649065 3.53887827 5.10000551], sL(w) = 0.6807658937065321\n","Iterations 846: w: [0.83608784 2.73738171 2.78653313 3.53896863 5.09998496], sL(w) = 0.6807903898546127\n","Iterations 847: w: [0.8361199  2.73723731 2.78657556 3.53905887 5.09996443], sL(w) = 0.680814852686377\n","Iterations 848: w: [0.83615193 2.73709311 2.78661793 3.53914899 5.09994393], sL(w) = 0.6808392822846878\n","Iterations 849: w: [0.83618391 2.7369491  2.78666024 3.53923898 5.09992346], sL(w) = 0.6808636787348629\n","Iterations 850: w: [0.83621584 2.7368053  2.78670249 3.53932885 5.09990302], sL(w) = 0.68088804212014\n","Iterations 851: w: [0.83624773 2.73666169 2.78674468 3.5394186  5.09988261], sL(w) = 0.6809123725242389\n","Iterations 852: w: [0.83627958 2.73651827 2.78678682 3.53950822 5.09986223], sL(w) = 0.6809366700301256\n","Iterations 853: w: [0.83631138 2.73637506 2.78682889 3.53959772 5.09984187], sL(w) = 0.6809609347208541\n","Iterations 854: w: [0.83634314 2.73623203 2.78687092 3.5396871  5.09982154], sL(w) = 0.6809851666788238\n","Iterations 855: w: [0.83637486 2.73608921 2.78691288 3.53977636 5.09980124], sL(w) = 0.6810093659868476\n","Iterations 856: w: [0.83640653 2.73594657 2.78695479 3.53986549 5.09978096], sL(w) = 0.6810335327262043\n","Iterations 857: w: [0.83643817 2.73580413 2.78699664 3.53995451 5.09976072], sL(w) = 0.6810576669788115\n","Iterations 858: w: [0.83646975 2.73566189 2.78703843 3.5400434  5.0997405 ], sL(w) = 0.6810817688262727\n","Iterations 859: w: [0.8365013  2.73551984 2.78708017 3.54013217 5.09972031], sL(w) = 0.6811058383494343\n","Iterations 860: w: [0.8365328  2.73537798 2.78712185 3.54022082 5.09970014], sL(w) = 0.6811298756290102\n","Iterations 861: w: [0.83656426 2.73523631 2.78716347 3.54030936 5.09968001], sL(w) = 0.6811538807457737\n","Iterations 862: w: [0.83659568 2.73509483 2.78720504 3.54039777 5.0996599 ], sL(w) = 0.6811778537794552\n","Iterations 863: w: [0.83662705 2.73495355 2.78724655 3.54048606 5.09963982], sL(w) = 0.6812017948099544\n","Iterations 864: w: [0.83665838 2.73481245 2.787288   3.54057424 5.09961976], sL(w) = 0.681225703917412\n","Iterations 865: w: [0.83668967 2.73467155 2.7873294  3.54066229 5.09959974], sL(w) = 0.6812495811809054\n","Iterations 866: w: [0.83672092 2.73453083 2.78737075 3.54075023 5.09957974], sL(w) = 0.6812734266796853\n","Iterations 867: w: [0.83675212 2.7343903  2.78741203 3.54083805 5.09955976], sL(w) = 0.6812972404919135\n","Iterations 868: w: [0.83678329 2.73424997 2.78745327 3.54092575 5.09953982], sL(w) = 0.6813210226964185\n","Iterations 869: w: [0.83681441 2.73410982 2.78749445 3.54101333 5.0995199 ], sL(w) = 0.6813447733713514\n","Iterations 870: w: [0.83684549 2.73396986 2.78753557 3.5411008  5.0995    ], sL(w) = 0.6813684925944241\n","Iterations 871: w: [0.83687652 2.73383008 2.78757664 3.54118815 5.09948014], sL(w) = 0.6813921804438683\n","Iterations 872: w: [0.83690752 2.73369049 2.78761765 3.54127538 5.0994603 ], sL(w) = 0.6814158369960578\n","Iterations 873: w: [0.83693847 2.73355109 2.78765861 3.54136249 5.09944048], sL(w) = 0.681439462328653\n","Iterations 874: w: [0.83696939 2.73341188 2.78769951 3.54144949 5.0994207 ], sL(w) = 0.6814630565183264\n","Iterations 875: w: [0.83700026 2.73327285 2.78774036 3.54153638 5.09940094], sL(w) = 0.6814866196413941\n","Iterations 876: w: [0.83703109 2.733134   2.78778115 3.54162314 5.0993812 ], sL(w) = 0.6815101517742622\n","Iterations 877: w: [0.83706188 2.73299534 2.7878219  3.5417098  5.09936149], sL(w) = 0.6815336529926052\n","Iterations 878: w: [0.83709263 2.73285686 2.78786258 3.54179633 5.09934181], sL(w) = 0.6815571233720785\n","Iterations 879: w: [0.83712334 2.73271857 2.78790321 3.54188276 5.09932216], sL(w) = 0.6815805629886342\n","Iterations 880: w: [0.83715401 2.73258046 2.78794379 3.54196906 5.09930253], sL(w) = 0.6816039719172199\n","Iterations 881: w: [0.83718463 2.73244253 2.78798432 3.54205526 5.09928292], sL(w) = 0.6816273502324895\n","Iterations 882: w: [0.83721522 2.73230479 2.78802479 3.54214134 5.09926335], sL(w) = 0.6816506980088014\n","Iterations 883: w: [0.83724576 2.73216723 2.78806521 3.5422273  5.0992438 ], sL(w) = 0.6816740153206262\n","Iterations 884: w: [0.83727627 2.73202984 2.78810558 3.54231316 5.09922427], sL(w) = 0.6816973022424937\n","Iterations 885: w: [0.83730673 2.73189264 2.78814589 3.5423989  5.09920477], sL(w) = 0.6817205588479974\n","Iterations 886: w: [0.83733716 2.73175562 2.78818615 3.54248452 5.0991853 ], sL(w) = 0.681743785210388\n","Iterations 887: w: [0.83736754 2.73161878 2.78822635 3.54257004 5.09916585], sL(w) = 0.681766981403055\n","Iterations 888: w: [0.83739789 2.73148212 2.78826651 3.54265544 5.09914642], sL(w) = 0.6817901474992514\n","Iterations 889: w: [0.83742819 2.73134564 2.78830661 3.54274073 5.09912703], sL(w) = 0.6818132835713778\n","Iterations 890: w: [0.83745846 2.73120934 2.78834666 3.54282591 5.09910766], sL(w) = 0.6818363896925813\n","Iterations 891: w: [0.83748869 2.73107321 2.78838665 3.54291098 5.09908831], sL(w) = 0.6818594659340357\n","Iterations 892: w: [0.83751887 2.73093726 2.7884266  3.54299593 5.09906899], sL(w) = 0.6818825123690369\n","Iterations 893: w: [0.83754902 2.73080149 2.78846649 3.54308078 5.09904969], sL(w) = 0.6819055290683795\n","Iterations 894: w: [0.83757913 2.7306659  2.78850633 3.54316551 5.09903042], sL(w) = 0.6819285161037953\n","Iterations 895: w: [0.83760919 2.73053049 2.78854612 3.54325014 5.09901118], sL(w) = 0.6819514735467572\n","Iterations 896: w: [0.83763922 2.73039525 2.78858586 3.54333465 5.09899196], sL(w) = 0.6819744014679779\n","Iterations 897: w: [0.83766921 2.73026018 2.78862554 3.54341906 5.09897276], sL(w) = 0.6819972999381314\n","Iterations 898: w: [0.83769916 2.73012529 2.78866518 3.54350335 5.09895359], sL(w) = 0.6820201690280819\n","Iterations 899: w: [0.83772907 2.72999058 2.78870476 3.54358754 5.09893444], sL(w) = 0.6820430088076399\n","Iterations 900: w: [0.83775895 2.72985604 2.78874429 3.54367161 5.09891532], sL(w) = 0.6820658193467822\n","Iterations 901: w: [0.83778878 2.72972167 2.78878377 3.54375558 5.09889623], sL(w) = 0.6820886007158476\n","Iterations 902: w: [0.83781858 2.72958748 2.7888232  3.54383944 5.09887716], sL(w) = 0.6821113529841928\n","Iterations 903: w: [0.83784833 2.72945346 2.78886258 3.54392319 5.09885811], sL(w) = 0.6821340762203022\n","Iterations 904: w: [0.83787805 2.72931961 2.7889019  3.54400683 5.09883909], sL(w) = 0.6821567704942543\n","Iterations 905: w: [0.83790773 2.72918594 2.78894118 3.54409037 5.09882009], sL(w) = 0.6821794358741888\n","Iterations 906: w: [0.83793737 2.72905244 2.78898041 3.54417379 5.09880112], sL(w) = 0.6822020724289576\n","Iterations 907: w: [0.83796698 2.72891911 2.78901958 3.54425711 5.09878217], sL(w) = 0.6822246802264229\n","Iterations 908: w: [0.83799654 2.72878595 2.78905871 3.54434033 5.09876325], sL(w) = 0.6822472593348481\n","Iterations 909: w: [0.83802607 2.72865296 2.78909779 3.54442344 5.09874435], sL(w) = 0.6822698098224061\n","Iterations 910: w: [0.83805556 2.72852014 2.78913681 3.54450644 5.09872547], sL(w) = 0.6822923317563242\n","Iterations 911: w: [0.83808501 2.72838749 2.78917579 3.54458933 5.09870662], sL(w) = 0.6823148252040473\n","Iterations 912: w: [0.83811443 2.72825501 2.78921472 3.54467212 5.09868779], sL(w) = 0.6823372902325554\n","Iterations 913: w: [0.83814381 2.7281227  2.78925359 3.5447548  5.09866899], sL(w) = 0.682359726909001\n","Iterations 914: w: [0.83817314 2.72799056 2.78929242 3.54483738 5.09865021], sL(w) = 0.6823821353000908\n","Iterations 915: w: [0.83820245 2.72785859 2.7893312  3.54491985 5.09863146], sL(w) = 0.6824045154722795\n","Iterations 916: w: [0.83823171 2.72772679 2.78936993 3.54500222 5.09861272], sL(w) = 0.6824268674918242\n","Iterations 917: w: [0.83826094 2.72759515 2.7894086  3.54508448 5.09859402], sL(w) = 0.6824491914241914\n","Iterations 918: w: [0.83829013 2.72746368 2.78944724 3.54516664 5.09857533], sL(w) = 0.6824714873357911\n","Iterations 919: w: [0.83831928 2.72733237 2.78948582 3.54524869 5.09855667], sL(w) = 0.6824937552918278\n","Iterations 920: w: [0.8383484  2.72720124 2.78952435 3.54533064 5.09853804], sL(w) = 0.6825159953578569\n","Iterations 921: w: [0.83837748 2.72707026 2.78956283 3.54541248 5.09851943], sL(w) = 0.6825382075987617\n","Iterations 922: w: [0.83840652 2.72693946 2.78960127 3.54549423 5.09850084], sL(w) = 0.6825603920793407\n","Iterations 923: w: [0.83843552 2.72680882 2.78963965 3.54557587 5.09848227], sL(w) = 0.6825825488644954\n","Iterations 924: w: [0.83846449 2.72667834 2.78967799 3.5456574  5.09846373], sL(w) = 0.6826046780178343\n","Iterations 925: w: [0.83849342 2.72654803 2.78971628 3.54573883 5.09844521], sL(w) = 0.6826267796043707\n","Iterations 926: w: [0.83852232 2.72641788 2.78975453 3.54582017 5.09842672], sL(w) = 0.6826488536886555\n","Iterations 927: w: [0.83855118 2.7262879  2.78979272 3.54590139 5.09840825], sL(w) = 0.6826709003333554\n","Iterations 928: w: [0.83858    2.72615808 2.78983087 3.54598252 5.0983898 ], sL(w) = 0.682692919602703\n","Iterations 929: w: [0.83860879 2.72602842 2.78986896 3.54606355 5.09837137], sL(w) = 0.6827149115592268\n","Iterations 930: w: [0.83863754 2.72589892 2.78990701 3.54614447 5.09835297], sL(w) = 0.6827368762668043\n","Iterations 931: w: [0.83866625 2.72576959 2.78994502 3.54622529 5.09833459], sL(w) = 0.6827588137880831\n","Iterations 932: w: [0.83869493 2.72564042 2.78998297 3.54630601 5.09831623], sL(w) = 0.6827807241853479\n","Iterations 933: w: [0.83872357 2.72551141 2.79002088 3.54638663 5.0982979 ], sL(w) = 0.6828026075222541\n","Iterations 934: w: [0.83875218 2.72538256 2.79005874 3.54646715 5.09827959], sL(w) = 0.6828244638600208\n","Iterations 935: w: [0.83878075 2.72525387 2.79009656 3.54654757 5.0982613 ], sL(w) = 0.6828462932611659\n","Iterations 936: w: [0.83880929 2.72512534 2.79013432 3.54662789 5.09824304], sL(w) = 0.682868095787251\n","Iterations 937: w: [0.83883779 2.72499697 2.79017204 3.54670811 5.0982248 ], sL(w) = 0.6828898715002949\n","Iterations 938: w: [0.83886625 2.72486876 2.79020972 3.54678823 5.09820658], sL(w) = 0.6829116204609765\n","Iterations 939: w: [0.83889468 2.72474071 2.79024734 3.54686825 5.09818838], sL(w) = 0.6829333427316046\n","Iterations 940: w: [0.83892308 2.72461282 2.79028492 3.54694817 5.09817021], sL(w) = 0.6829550383728152\n","Iterations 941: w: [0.83895143 2.72448509 2.79032245 3.54702799 5.09815206], sL(w) = 0.6829767074455672\n","Iterations 942: w: [0.83897976 2.72435751 2.79035994 3.54710771 5.09813393], sL(w) = 0.682998350009652\n","Iterations 943: w: [0.83900805 2.7242301  2.79039738 3.54718733 5.09811582], sL(w) = 0.6830199661264035\n","Iterations 944: w: [0.8390363  2.72410284 2.79043478 3.54726686 5.09809774], sL(w) = 0.6830415558557064\n","Iterations 945: w: [0.83906452 2.72397573 2.79047212 3.54734629 5.09807968], sL(w) = 0.6830631192574417\n","Iterations 946: w: [0.8390927  2.72384879 2.79050943 3.54742562 5.09806164], sL(w) = 0.6830846563918177\n","Iterations 947: w: [0.83912085 2.723722   2.79054668 3.54750485 5.09804362], sL(w) = 0.6831061673181803\n","Iterations 948: w: [0.83914896 2.72359536 2.79058389 3.54758398 5.09802563], sL(w) = 0.683127652095687\n","Iterations 949: w: [0.83917704 2.72346888 2.79062106 3.54766302 5.09800766], sL(w) = 0.6831491107844271\n","Iterations 950: w: [0.83920509 2.72334256 2.79065818 3.54774196 5.09798971], sL(w) = 0.6831705434424955\n","Iterations 951: w: [0.8392331  2.72321639 2.79069525 3.54782081 5.09797178], sL(w) = 0.6831919501292197\n","Iterations 952: w: [0.83926107 2.72309038 2.79073228 3.54789955 5.09795387], sL(w) = 0.6832133309032897\n","Iterations 953: w: [0.83928902 2.72296451 2.79076927 3.5479782  5.09793599], sL(w) = 0.6832346858231774\n","Iterations 954: w: [0.83931692 2.72283881 2.7908062  3.54805676 5.09791813], sL(w) = 0.6832560149468386\n","Iterations 955: w: [0.8393448  2.72271325 2.7908431  3.54813522 5.09790028], sL(w) = 0.6832773183327794\n","Iterations 956: w: [0.83937264 2.72258785 2.79087995 3.54821358 5.09788247], sL(w) = 0.6832985960381862\n","Iterations 957: w: [0.83940044 2.72246261 2.79091675 3.54829185 5.09786467], sL(w) = 0.6833198481212802\n","Iterations 958: w: [0.83942821 2.72233751 2.79095351 3.54837002 5.09784689], sL(w) = 0.6833410746394492\n","Iterations 959: w: [0.83945595 2.72221257 2.79099022 3.5484481  5.09782914], sL(w) = 0.6833622756496835\n","Iterations 960: w: [0.83948366 2.72208778 2.79102689 3.54852608 5.09781141], sL(w) = 0.683383451209289\n","Iterations 961: w: [0.83951133 2.72196314 2.79106352 3.54860397 5.0977937 ], sL(w) = 0.6834046013754821\n","Iterations 962: w: [0.83953896 2.72183865 2.7911001  3.54868176 5.09777601], sL(w) = 0.6834257262044623\n","Iterations 963: w: [0.83956657 2.72171431 2.79113664 3.54875946 5.09775834], sL(w) = 0.6834468257536606\n","Iterations 964: w: [0.83959414 2.72159012 2.79117313 3.54883707 5.09774069], sL(w) = 0.6834679000788502\n","Iterations 965: w: [0.83962167 2.72146608 2.79120958 3.54891458 5.09772307], sL(w) = 0.6834889492358126\n","Iterations 966: w: [0.83964918 2.72134219 2.79124598 3.548992   5.09770547], sL(w) = 0.6835099732812725\n","Iterations 967: w: [0.83967665 2.72121845 2.79128234 3.54906932 5.09768788], sL(w) = 0.6835309722705746\n","Iterations 968: w: [0.83970408 2.72109486 2.79131866 3.54914656 5.09767032], sL(w) = 0.6835519462594755\n","Iterations 969: w: [0.83973149 2.72097142 2.79135493 3.54922369 5.09765278], sL(w) = 0.6835728953034501\n","Iterations 970: w: [0.83975886 2.72084813 2.79139116 3.54930074 5.09763527], sL(w) = 0.6835938194582516\n","Iterations 971: w: [0.83978619 2.72072498 2.79142735 3.54937769 5.09761777], sL(w) = 0.6836147187781749\n","Iterations 972: w: [0.8398135  2.72060198 2.79146349 3.54945456 5.09760029], sL(w) = 0.6836355933189713\n","Iterations 973: w: [0.83984077 2.72047913 2.79149959 3.54953133 5.09758284], sL(w) = 0.6836564431349422\n","Iterations 974: w: [0.83986801 2.72035643 2.79153565 3.549608   5.0975654 ], sL(w) = 0.6836772682806029\n","Iterations 975: w: [0.83989522 2.72023387 2.79157166 3.54968459 5.09754799], sL(w) = 0.6836980688103381\n","Iterations 976: w: [0.83992239 2.72011146 2.79160763 3.54976108 5.09753059], sL(w) = 0.6837188447787885\n","Iterations 977: w: [0.83994953 2.7199892  2.79164356 3.54983749 5.09751322], sL(w) = 0.6837395962394245\n","Iterations 978: w: [0.83997664 2.71986708 2.79167945 3.5499138  5.09749587], sL(w) = 0.6837603232465508\n","Iterations 979: w: [0.84000372 2.7197451  2.79171529 3.54999002 5.09747854], sL(w) = 0.6837810258532815\n","Iterations 980: w: [0.84003077 2.71962328 2.79175109 3.55006615 5.09746123], sL(w) = 0.6838017041135356\n","Iterations 981: w: [0.84005778 2.71950159 2.79178685 3.55014219 5.09744394], sL(w) = 0.6838223580809212\n","Iterations 982: w: [0.84008476 2.71938005 2.79182256 3.55021814 5.09742667], sL(w) = 0.6838429878084412\n","Iterations 983: w: [0.84011171 2.71925866 2.79185824 3.550294   5.09740942], sL(w) = 0.6838635933486742\n","Iterations 984: w: [0.84013862 2.71913741 2.79189387 3.55036977 5.0973922 ], sL(w) = 0.6838841747549366\n","Iterations 985: w: [0.84016551 2.7190163  2.79192945 3.55044545 5.09737499], sL(w) = 0.6839047320799216\n","Iterations 986: w: [0.84019236 2.71889533 2.791965   3.55052104 5.0973578 ], sL(w) = 0.6839252653754506\n","Iterations 987: w: [0.84021918 2.71877451 2.79200051 3.55059654 5.09734063], sL(w) = 0.6839457746944493\n","Iterations 988: w: [0.84024597 2.71865383 2.79203597 3.55067195 5.09732349], sL(w) = 0.6839662600893134\n","Iterations 989: w: [0.84027273 2.71853329 2.79207139 3.55074728 5.09730636], sL(w) = 0.6839867216115865\n","Iterations 990: w: [0.84029945 2.7184129  2.79210677 3.55082251 5.09728926], sL(w) = 0.684007159313187\n","Iterations 991: w: [0.84032615 2.71829264 2.79214211 3.55089766 5.09727217], sL(w) = 0.684027573245754\n","Iterations 992: w: [0.84035281 2.71817253 2.7921774  3.55097272 5.09725511], sL(w) = 0.684047963460915\n","Iterations 993: w: [0.84037944 2.71805256 2.79221266 3.55104769 5.09723806], sL(w) = 0.6840683300098186\n","Iterations 994: w: [0.84040604 2.71793273 2.79224787 3.55112257 5.09722103], sL(w) = 0.684088672944051\n","Iterations 995: w: [0.84043261 2.71781304 2.79228304 3.55119736 5.09720403], sL(w) = 0.6841089923144801\n","Iterations 996: w: [0.84045915 2.71769349 2.79231817 3.55127207 5.09718704], sL(w) = 0.6841292881719074\n","Iterations 997: w: [0.84048566 2.71757408 2.79235327 3.55134669 5.09717008], sL(w) = 0.6841495605665895\n","Iterations 998: w: [0.84051214 2.71745481 2.79238831 3.55142122 5.09715313], sL(w) = 0.6841698095499669\n","Iterations 999: w: [0.84053858 2.71733567 2.79242332 3.55149567 5.09713621], sL(w) = 0.684190035171429\n"]}]},{"cell_type":"markdown","source":["## Optimizer"],"metadata":{"id":"60N4UCMrtzae"}},{"cell_type":"code","source":["def sgd(w, dw, config=None):\n","    \"\"\"\n","    config format:\n","    - learning rate: Scalar learning rate\n","    \"\"\"\n","    if config is None:\n","        config = {}\n","    config.setdefault('learning_rate', 1e-2)\n","    w -= config['learning_rate'] * dw\n","    return w, config"],"metadata":{"id":"-L2m7jautR3m","executionInfo":{"status":"ok","timestamp":1643026171821,"user_tz":-420,"elapsed":9,"user":{"displayName":"Phạm Đức Thể","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0DbvnWDzLWfReqJkA_CpifKsPoGK79L7Ow3Jg1w=s64","userId":"09005724978234100310"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Softmax"],"metadata":{"id":"539KMOaDt8T0"}},{"cell_type":"code","source":["def softmax_naive():\n","  loss = 0.0\n","  reg = 0.02\n","  W = np.array([[1.0, 0.7, 3.0], [4.0, 5.0, 0.6]])\n","  X = np.array([[0.2, 0.3], [0.4, 0.1], [0.4, 0.5], [0.7, 0.2]])\n","  scores = X @ W\n","  y = np.array([1, 0, 2, 0])\n","  num_train = X.shape[0]\n","  num_classes = W.shape[1]\n","  dW = np.zeros_like(W)\n","  for i in range(num_train):\n","    f = scores[i] - np.max(scores[i])\n","    softmax = np.exp(f)/np.sum(np.exp(f))\n","    print(softmax, '\\n\\n')\n","    loss += -np.log(softmax[y[i]])\n","    for j in range(num_classes):\n","      dW[:,j] += X[i] * (softmax[j] - (j == y[i]))\n","\n","  # Average\n","  loss /= num_train\n","  dW /= num_train\n","\n","  # Regularization\n","  loss += reg * np.sum(W * W)\n","  dW += reg * 2 * W\n","  return loss, dW\n","\n","\n","def softmax_loss_vectorized(W, X, y, reg):\n","\n","  loss = 0.0\n","  dW = np.zeros_like(W)\n","  num_train = X.shape[0]\n","  scores = X @ W\n","  scores = scores - np.max(scores, axis=1, keepdims=True)\n","\n","\n","  # Softmax_losss\n","  sum_exp = np.exp(scores).sum(axis=1, keepdims=True)\n","  softmax_matrix = np.exp(scores)/sum_exp\n","  loss = np.sum(-np.log(softmax_matrix[np.arange(num_train), y]))\n","\n","  softmax_matrix[np.arange(num_train), y] -= 1\n","  dW = X.T @ softmax_matrix\n","  loss /= num_train\n","  dW /= num_train\n","\n","  # Regularization\n","  loss += reg * np.sum(W*W)\n","  dW += reg * 2 * W\n","  return loss, dW"],"metadata":{"id":"t78eyZOCtR7I","executionInfo":{"status":"ok","timestamp":1643026171824,"user_tz":-420,"elapsed":10,"user":{"displayName":"Phạm Đức Thể","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0DbvnWDzLWfReqJkA_CpifKsPoGK79L7Ow3Jg1w=s64","userId":"09005724978234100310"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## Neural Network"],"metadata":{"id":"lCkpjjeJuFfs"}},{"cell_type":"code","source":["class ShallowNeuralNet(object):\n","    # Implementing two layer nets\n","    def __init__(self, input_size, hidden_size, output_size, std=1e-4):\n","\n","        \"\"\"\n","        W1 : first layer weights, shape (D, H)\n","        b1 : first layer biases, shape (H, )\n","        W2 : second layer weights, shape (H, C)\n","        b2 : second layer biases, shape (C, )\n","        \"\"\"\n","\n","        self.params = {}\n","        self.params['W1'] = std * np.random.randn(input_size, hidden_size)\n","        self.params['b1'] = np.zeros(hidden_size)\n","        self.params['W2'] = std * np.random.randn(hidden_size, output_size)\n","        self.params['b2'] = np.zeros(output_size)\n","\n","    def loss(self, X, y=None, reg=0.0):\n","        W1, b1 = self.params['W1'], self.params['b1']\n","        W2, b2 = self.params['W2'], self.params['b2']\n","        N, D = X.shape\n","\n","        # Forward propagation\n","        Z1 = X @ W1 + b1\n","        A1 = np.maximum(0, Z1)  # Relu\n","        Z2 = A1 @ W2 + b2\n","\n","        if y is None:\n","            scores = Z2\n","            return scores\n","\n","        Z2 -= np.max(Z2, axis=1, keepdims=True)\n","        Z2_exp = np.exp(Z2)\n","        scores = Z2_exp / np.sum(Z2_exp, axis=1, keepdims=True)\n","        loss = np.sum(-np.log(scores[np.arange(N), y]))\n","        loss /= N\n","        loss += reg * (np.sum(W2 * W2) + np.sum(W1 * W1))\n","\n","        # Backward propagation\n","        grads = {}\n","        scores[np.arange(N), y] -= 1\n","        scores /= N\n","\n","        # W2 gradient\n","        dW2 = A1.T @ scores\n","\n","        # b2 gradient\n","        db2 = scores.sum(axis=0)\n","\n","        # W1 gradient\n","        dA1 = scores @ (W2.T)\n","        dZ1 = dA1 * (Z1 > 0)\n","        dW1 = X.T @ dZ1\n","\n","        # b1 gradient\n","        db1 = dZ1.sum(axis=0)\n","\n","        # regularization gradient\n","        dW1 += reg * 2 * W1\n","        dW2 += reg * 2 * W2\n","\n","        grads = {'W1': dW1, 'b1': db1, 'W2': dW2, 'b2': db2}\n","\n","        return loss, grads\n","\n","    def fit(self, X, y, X_val, y_val, lr=1e-3, lr_decay=0.95, reg=5e-6, num_iters=100, batch_size=200, verbose=False):\n","        num_train = X.shape[0]\n","        print(X.shape)\n","        iter_per_epoch = max(num_train / batch_size, 1)\n","        # Use SGD to optimize the parameters in self.model\n","        loss_history = []\n","        train_acc_history = []\n","        val_acc_history = []\n","\n","        for iter in range(num_iters):\n","            X_batch = None\n","            y_batch = None\n","\n","            batches_indices = np.random.choice(num_train, batch_size)\n","            X_batch = X[batches_indices]\n","            y_batch = y[batches_indices]\n","\n","            # Compute loss and gradients using the current batches\n","            loss, grads = self.loss(X_batch, y=y_batch, reg=reg)\n","            loss_history.append(loss)\n","\n","            # Update parameters\n","            for key in self.params:\n","                self.params[key] -= lr * grads[key]\n","\n","            if verbose and iter % 100 == 0:\n","                print('iteration %d / %d: loss %f' % (iter, num_iters, loss))\n","\n","            # Every epoch, check train and val accuracy and decay learning rate\n","            if iter % iter_per_epoch == 0:\n","                train_acc = (self.predict(X_batch) == y_batch).mean()\n","                val_acc = (self.predict(X_val) == y_val).mean()\n","                train_acc_history.append(train_acc)\n","                val_acc_history.append(val_acc)\n","\n","                # Decay learning rate\n","                lr *= lr_decay\n","\n","        return {\n","                'loss_history': loss_history,\n","                'train_acc_history': train_acc_history,\n","                'val_acc_history': val_acc_history\n","                }\n","\n","    def predict(self, X):\n","        y_preds = np.argmax(self.loss(X), axis=1)\n","        return y_preds\n","\n","\n","\n","X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data()\n","\n","input_size = 32 * 32 * 3\n","hidden_size = 50\n","num_classes = 10\n","\n","net = ShallowNeuralNet(input_size, hidden_size, num_classes)\n","\n","# Train the network\n","\n","model = net.fit(X_train, y_train, X_val, y_val, num_iters=1000, batch_size=200, verbose=True)\n","val_acc = (net.predict(X_val) == y_val).mean()\n","print('Validation accuracy: ', val_acc)\n","\n","# Plot the loss function and train / validation accuracies\n","plt.subplot(2, 1, 1)\n","plt.plot(model['loss_history'])\n","plt.title('Loss history')\n","plt.xlabel('Iteration')\n","plt.ylabel('Loss')\n","\n","plt.subplot(2, 1, 2)\n","plt.plot(model['train_acc_history'], label='train')\n","plt.plot(model['val_acc_history'], label='val')\n","plt.title('Classification accuracy history')\n","plt.xlabel('Epoch')\n","plt.ylabel('Classification accuracy')\n","plt.legend()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":521},"id":"2xn86GCduSqF","executionInfo":{"status":"ok","timestamp":1643026962022,"user_tz":-420,"elapsed":21768,"user":{"displayName":"Phạm Đức Thể","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0DbvnWDzLWfReqJkA_CpifKsPoGK79L7Ow3Jg1w=s64","userId":"09005724978234100310"}},"outputId":"1b4eca06-a89d-4d59-b2e7-5dab26efc6f9"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["(49000, 3072)\n","iteration 0 / 1000: loss 2.302598\n","iteration 100 / 1000: loss 1.987708\n","iteration 200 / 1000: loss 1.832592\n","iteration 300 / 1000: loss 1.662610\n","iteration 400 / 1000: loss 1.714056\n","iteration 500 / 1000: loss 1.548150\n","iteration 600 / 1000: loss 1.425831\n","iteration 700 / 1000: loss 1.520870\n","iteration 800 / 1000: loss 1.589222\n","iteration 900 / 1000: loss 1.435368\n","Validation accuracy:  0.488\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["## DeepNet"],"metadata":{"id":"tl7k5KaMuWU2"}},{"cell_type":"code","source":["class DeepNet(object):\n","    def __init__(self, hidden_layers, input_size=3*32*32, num_classes=10, reg=0.0, std=1e-2):\n","        layers = np.hstack([input_size, hidden_layers, num_classes])\n","        self.params = {}\n","        self.reg = reg\n","        self.num_layers = 1 + len(hidden_layers)\n","        for i in range(self.num_layers):\n","            self.params['W'+str(i+1)] = std*np.random.randn(layers[i], layers[i+1])\n","            self.params['b'+str(i+1)] = np.zeros(layers[i+1])\n","        for k, v in self.params.items():\n","            self.params[k] = v.astype(np.float32)\n","\n","    def loss(self, X, y=None):\n","        x = X.astype(np.float32)\n","        mode = 'test' if y is None else 'train'\n","        scores = None\n","        caches = []\n","        for i in range(self.num_layers - 1):\n","            w = self.params['W'+str(i+1)]\n","            b = self.params['b'+str(i+1)]\n","            Z, linear_cache = linear_forward(x, w, b)\n","            A, relu_cache = relu_forward(Z)\n","            x, cache = A, (linear_cache, relu_cache)\n","            caches.append(cache)\n","        w = self.params['W'+str(self.num_layers)]\n","        b = self.params['b'+str(self.num_layers)]\n","        scores, cache = linear_forward(x, w, b)\n","        caches.append(cache)\n","\n","        if mode == 'test':\n","            return scores\n","\n","        # Calculate loss\n","        loss, grads = 0.0, {}\n","        loss, softmax_grad = softmax_loss(scores, y)\n","        for i in range(self.num_layers):\n","            w = self.params['W'+str(i+1)]\n","            loss += 0.5 * self.reg * np.sum(w * w)\n","\n","        # Calculate gradient\n","        dout = softmax_grad\n","        dout, dw, db = linear_backward(dout, caches[self.num_layers - 1])\n","        grads['W'+str(self.num_layers)] = dw + self.reg * self.params['W'+str(self.num_layers)]\n","        grads['b'+str(self.num_layers)] = db\n","\n","        for i in range(self.num_layers - 2, -1, -1):\n","            linear_cache, relu_cache = caches[i]\n","            # relu\n","            dout = relu_backward(dout, relu_cache)\n","            # linear\n","            dx, dw, db = linear_backward(dout, linear_cache)\n","            grads['W'+str(i+1)] = dw + self.reg * self.params['W'+str(i+1)]\n","            grads['b'+str(i+1)] = db\n","            dout = dx\n","\n","        return loss, grads"],"metadata":{"id":"VOXd3aycuSuN","executionInfo":{"status":"ok","timestamp":1643026978228,"user_tz":-420,"elapsed":625,"user":{"displayName":"Phạm Đức Thể","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0DbvnWDzLWfReqJkA_CpifKsPoGK79L7Ow3Jg1w=s64","userId":"09005724978234100310"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["## Classifier"],"metadata":{"id":"BisWaOlUuj55"}},{"cell_type":"code","source":["class Classifier(object):\n","    def __init__(self, model, data, **kwargs):\n","        self.model = model\n","        self.X_train = data['X_train']\n","        self.y_train = data['y_train']\n","        self.X_val = data['X_val']\n","        self.y_val = data['y_val']\n","\n","        # Keyword arguments\n","        self.lr_decay = kwargs.pop('lr_decay', 1.0)\n","        self.batch_size = kwargs.pop('batch_size', 100)\n","        self.num_epochs = kwargs.pop('num_epochs', 10)\n","        self.num_train_samples = kwargs.pop('num_train_samples', 1000)\n","        self.num_val_samples = kwargs.pop('num_val_samples', None)\n","        self.update_rule = kwargs.pop('update_rule', 'sgd')\n","        self.optim_config = kwargs.pop('optim_config', {})\n","        self.print_every = kwargs.pop('print_every', 10)\n","        self.verbose = kwargs.pop('verbose', True)\n","\n","        if len(kwargs) > 0:\n","            extra = ', '.join('\"%s\"' % k for k in list(kwargs.keys()))\n","            raise ValueError('Unrecognized arguments %s' % extra)\n","\n","        self.epoch = 0\n","        self.best_val_acc = 0\n","        self.best_params = {}\n","        self.loss_history = []\n","        self.train_acc_history = []\n","        self.val_acc_history = []\n","        self.optim_configs = {}\n","        for p in self.model.params:\n","            d = {k: v for k, v in self.optim_config.items()}\n","            self.optim_configs[p] = d\n","        self.update_rule = getattr(optimizer, self.update_rule)\n","\n","    def step(self):\n","        # Make a minibatch of training\n","        num_train = self.X_train.shape[0]\n","        mask = np.random.choice(num_train, self.batch_size)\n","        X_batch = self.X_train[mask]\n","        y_batch = self.y_train[mask]\n","\n","        # Compute loss and gradients\n","        loss, grads = self.model.loss(X_batch, y_batch)\n","        self.loss_history.append(loss)\n","\n","        # Update parameters\n","        for p, w in self.model.params.items():\n","            dw = grads[p]\n","            config = self.optim_configs[p]\n","            w_new, config_new = self.update_rule(w, dw, config)\n","            self.model.params[p] = w_new\n","            self.optim_configs[p] = config_new\n","\n","    def fit(self):\n","        num_train = self.X_train.shape[0]\n","        iterations_per_epoch = max(num_train // self.batch_size, 1)\n","        num_iters = self.num_epochs * iterations_per_epoch\n","\n","        for i in range(num_iters):\n","            self.step()\n","\n","            # Print training loss\n","            if self.verbose and i % self.print_every == 0:\n","                print('(Iteration %d / %d) loss: %f' % (\n","                       i + 1, num_iters, self.loss_history[-1]))\n","\n","            # At the end of every epoch, increase the epoch counter and\n","            # decay learning rate\n","            epoch_end = ((i + 1) % iterations_per_epoch == 0)\n","            if epoch_end:\n","                self.epoch += 1\n","                for k in self.optim_configs:\n","                    self.optim_configs[k]['learning_rate'] *= self.lr_decay\n","            # Check train and val accuracy on the first iteration, the last iteration, and\n","            # at the end of each epoch\n","            first_iters = (i == 0)\n","            last_iters = (i == num_iters - 1)\n","            if first_iters or last_iters or epoch_end:\n","                train_acc = self.accuracy(self.X_train, self.y_train, num_samples=self.num_train_samples)\n","                val_acc = self.accuracy(self.X_val, self.y_val, num_samples=self.num_val_samples)\n","                self.train_acc_history.append(train_acc)\n","                self.val_acc_history.append(val_acc)\n","\n","                if self.verbose:\n","                    print('(Epoch %d / %d) train acc: %f; val_acc: %f' % (\n","                           self.epoch, self.num_epochs, train_acc, val_acc))\n","\n","                # Keep track of the best model\n","                if val_acc > self.best_val_acc:\n","                    self.best_val_acc = val_acc\n","                    self.best_params = {}\n","                    for k, v in self.model.params.items():\n","                        self.best_params[k] = v.copy()\n","\n","        # At the end of training swap the best params into the model\n","        self.model.params = self.best_params\n","\n","    def accuracy(self, X, y, num_samples=None, batch_size=100):\n","        \"\"\"\n","        X: data, of shape (N, d_1, d_2, ..., d_k)\n","        y: labels, of shape(N, )\n","        num_samples: if not None, subsample the data and only test the model one num_samples\n","                        datapoints\n","        batch_size: split X and y into batches to avoid too much memmory\n","        \"\"\"\n","        N = X.shape[0]\n","        if num_samples is not None and N > num_samples:\n","            mask = np.random.choice(N, num_samples)\n","            N = num_samples\n","            X = X[mask]\n","            y = y[mask]\n","\n","        num_batches = N // batch_size\n","        if N % batch_size != 0:\n","            num_batches += 1\n","        y_pred = []\n","        for i in range(num_batches):\n","            start = i * batch_size\n","            end = (i + 1) * batch_size\n","            scores = self.model.loss(X[start:end])\n","            y_pred.append(np.argmax(scores, axis=1))\n","        y_pred = np.hstack(y_pred)\n","        acc = np.mean(y_pred == y)\n","        return float(acc)"],"metadata":{"id":"PaKiWcxGuSxQ","executionInfo":{"status":"ok","timestamp":1643029659075,"user_tz":-420,"elapsed":713,"user":{"displayName":"Phạm Đức Thể","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0DbvnWDzLWfReqJkA_CpifKsPoGK79L7Ow3Jg1w=s64","userId":"09005724978234100310"}}},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":["## Final"],"metadata":{"id":"JXi-3j6_uu5l"}},{"cell_type":"code","source":["data = get_CIFAR10_data()\n","\n","num_train = 100\n","small_data = {\n","    'X_train': data[0][:num_train],\n","    'y_train': data[1][:num_train],\n","    'X_val': data[2],\n","    'y_val': data[3],\n","}\n","\n","weight_scale = 2e-4\n","learning_rate = 3e-1\n","\n","# Create model\n","model = DeepNet([100, 100, 100, 200], std=weight_scale)\n","machine = Classifier(model, small_data, print_every=10,\n","                     num_epochs=20, batch_size=25,\n","                     update_rule='sgd',\n","                     optim_config={'learning_rate': learning_rate})\n","# Train model\n","machine.fit()\n","plt.plot(machine.loss_history, 'o')\n","plt.title('Training loss history')\n","plt.xlabel('Iteration')\n","plt.ylabel('Training loss')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":385},"id":"VM3um9cbuS0I","executionInfo":{"status":"error","timestamp":1643029665767,"user_tz":-420,"elapsed":3795,"user":{"displayName":"Phạm Đức Thể","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0DbvnWDzLWfReqJkA_CpifKsPoGK79L7Ow3Jg1w=s64","userId":"09005724978234100310"}},"outputId":"c926fd73-b907-4035-9039-9c0959c4995a"},"execution_count":52,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-52-d18d572de48c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m                      \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                      \u001b[0mupdate_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                      optim_config={'learning_rate': learning_rate})\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mmachine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-51-2e6690799e3d>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, data, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim_configs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_rule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"]}]},{"cell_type":"code","source":["|"],"metadata":{"id":"M_D7rByZCrl_"},"execution_count":null,"outputs":[]}]}